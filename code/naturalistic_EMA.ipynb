{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturalistic EMA validation\n",
    "\n",
    "Applying the findings from the 4-state correlation work (EMA x UPDRS) onto real-life EMA data.\n",
    "\n",
    "Goals:\n",
    "- analyse real-life variation of EMA values\n",
    "    - inter-individual variation\n",
    "    - intra-individual variation, daily fluctuations, differences between days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import packages\n",
    "\n",
    "- document versions for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import importlib\n",
    "from itertools import product, compress\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.signal import welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "# print('sci-py', scipy.__version__)\n",
    "# print('sci-kit learn', sk.__version__)\n",
    "# print('matplotlib', plt_version)\n",
    "\n",
    "\"\"\"\n",
    "Python sys 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
    "pandas 2.1.1\n",
    "numpy 1.26.0\n",
    "\n",
    "from 16.09\n",
    "\n",
    "Python sys 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
    "pandas 2.3.2\n",
    "numpy 2.3.3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dbs_home repo\n",
    "from dbs_home.load_raw.main_load_raw import loadSubject \n",
    "import dbs_home.utils.helpers as home_helpers\n",
    "import dbs_home.utils.ema_utils as home_ema_utils\n",
    "import dbs_home.plot_data.plot_compliance as plot_home_compl\n",
    "import dbs_home.preprocessing.preparing_ema as home_ema_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from current repo\n",
    "from utils import load_utils, load_data, prep_data\n",
    "from plotting import plot_help\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Home-Data\n",
    "\n",
    "Use pre-operative sessions\n",
    "\n",
    "- use 9-point-converter\n",
    "- use direct. inverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import EMA home data from raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTS = ['pre-op', 'pre 3MFU', 'post 3MFU']\n",
    "\n",
    "sub_skip = [] # ['hm25',]  # skip full subject\n",
    "# skip per session\n",
    "ses_skip = [['hm20', 'ses03'],]\n",
    "# ses_skip = [['hm14', 'ses03']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_include = {m: {} for m in MOMENTS}\n",
    "\n",
    "for rec_moment in MOMENTS:\n",
    "\n",
    "    sel_info = home_helpers.select_sessions(target_session=rec_moment)\n",
    "    sel_info = sel_info.set_index(sel_info['study_id'],)\n",
    "    sel_sessions = {sub: ses for sub, ses in sel_info[['study_id', 'Session']].values}\n",
    "\n",
    "    for key, val in sel_sessions.items():\n",
    "        sessions_include[rec_moment][key] = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sessions_include.keys())\n",
    "print(sessions_include)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data\n",
    "\n",
    "dev for EMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(home_ema_utils)\n",
    "importlib.reload(load_data)\n",
    "importlib.reload(prep_data)\n",
    "importlib.reload(home_ema_prep)\n",
    "\n",
    "# load all combined data\n",
    "\n",
    "# SUBS_INCL = ['hm14']\n",
    "\n",
    "\n",
    "data = {m: {} for m in MOMENTS}\n",
    "\n",
    "for rec_moment, sub_sess in sessions_include.items():\n",
    "    # rec_moment contains 'pre-op', or 'pre 3MFU', 'post 3MFU', etc\n",
    "    for sub, ses in sub_sess.items():\n",
    "\n",
    "        if sub in sub_skip: continue\n",
    "                    \n",
    "        if [sub, ses] in ses_skip: continue\n",
    "                \n",
    "        ses_class = loadSubject(\n",
    "            sub=sub,\n",
    "            ses=ses,\n",
    "            incl_EMA=True,\n",
    "            incl_ACC=False,\n",
    "        )\n",
    "        temp_df = home_ema_utils.load_ema_df(sub_ses_class=ses_class)\n",
    "        # prepare\n",
    "        temp_df = home_ema_prep.prepare_ema_df(temp_df, ADD_MEANMOVE=True, INVERT_NEG_ITEMS=False,)\n",
    "        ### TODO: CHECK WHY NOT ALL SUBS ARE INVERTED PROPERLY\n",
    "\n",
    "        data[rec_moment][sub] = temp_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore naturalistic EMAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess EMA\n",
    "\n",
    "- merge scores\n",
    "- invert negative-items (higher = clinically better)\n",
    "- mean-correct EMA\n",
    "    - test different normalizations:\n",
    "        - normalize with grand-mean per sub\n",
    "        - normalize with session mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(prep_data)\n",
    "\n",
    "allsubs = []\n",
    "for mom in list(data.keys()): allsubs.extend(list(data[mom].keys()))\n",
    "allsubs = np.unique(allsubs)\n",
    "\n",
    "\n",
    "corr_data = {m: {} for m in MOMENTS}\n",
    "\n",
    "for sub in allsubs:\n",
    "\n",
    "    subdf = home_ema_prep.merge_sub_ema_df(datadict=data, sub=sub)\n",
    "    subdf = home_ema_prep.mean_correct_ema_df(subdf)\n",
    "\n",
    "    # split and palce back as moment dfs    \n",
    "    for moment in MOMENTS:\n",
    "        corr_data[moment][sub] = subdf[subdf['moment'] == moment].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize first EMA results full group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ITEMS = ['move_mean', 'walking', 'tremor']\n",
    "\n",
    "PLOT_CORR = False\n",
    "if PLOT_CORR: PLOT_DATADICT = corr_data\n",
    "else: PLOT_DATADICT = data\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 6))\n",
    "fname = 'motorItems_abs_perSub_perSes_1104'\n",
    "if PLOT_CORR: fname = fname.replace('abs', 'corr')\n",
    "\n",
    "x_margin = 2\n",
    "bin_w = 0.5\n",
    "\n",
    "fsize=14\n",
    "\n",
    "x_starts = {list(data.keys())[0]: 0}  # first moment starts at 0\n",
    "\n",
    "subcolors = plot_help.get_sub_colors(PLOT_DATADICT)\n",
    "\n",
    "\n",
    "for i_ax, col in enumerate(PLOT_ITEMS):\n",
    "\n",
    "    for i_mom, moment in enumerate(PLOT_DATADICT.keys()):\n",
    "\n",
    "        if PLOT_CORR and i_mom == 0: col = f'{col}_corr'\n",
    "\n",
    "        # loop over sub-dfs within moment and add specific column values\n",
    "        list_values = [tempdf[col].values for tempdf in PLOT_DATADICT[moment].values()]\n",
    "        box_subs = list(PLOT_DATADICT[moment].keys())  # subs included in this boxplot\n",
    "        # sort by sub id\n",
    "        i_sort = np.argsort(box_subs)\n",
    "        box_subs = [box_subs[i] for i in i_sort]\n",
    "        list_values = [list_values[i] for i in i_sort]\n",
    "\n",
    "        # drop NaN values in lists\n",
    "        list_values = [[v for v in l if not np.isnan(v)] for l in list_values]\n",
    "\n",
    "        # plot boxes for one moment\n",
    "        bp = axes[i_ax].boxplot(list_values, widths=bin_w,\n",
    "                           positions=x_starts[moment] + bin_w * np.arange(len(list_values)),\n",
    "                           patch_artist=True,)\n",
    "        if i_ax == 0:\n",
    "            if moment != list(PLOT_DATADICT.keys())[-1]:\n",
    "                x_starts[list(PLOT_DATADICT.keys())[i_mom + 1]] = x_starts[moment] + len(list_values) * bin_w + x_margin\n",
    "\n",
    "        # Loop over boxes\n",
    "        for patch, patchsub in zip(bp['boxes'], box_subs):\n",
    "            patch.set_facecolor(subcolors[patchsub])\n",
    "\n",
    "    # pretty plot\n",
    "    axes[i_ax].set_ylabel(f'{col}\\n(EMA answer)', size=fsize,)\n",
    "\n",
    "# pretty axes\n",
    "for ax in axes:\n",
    "    if not PLOT_CORR:\n",
    "        ax.set_ylim(0, 10)\n",
    "        ax.set_yticks(np.arange(1, 10, 2))\n",
    "        ax.set_yticklabels(np.arange(1, 10, 2))\n",
    "    else:\n",
    "        ax.set_ylim(-5, 5)\n",
    "        ax.set_yticks(np.arange(-4, 6, 2))\n",
    "        ax.set_yticklabels(np.arange(-4, 6, 2))\n",
    "\n",
    "    ax.set_xticks(list(x_starts.values()))\n",
    "    ax.set_xticklabels(list(x_starts.keys()))\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    ax.tick_params(axis='both', labelsize=fsize, size=fsize,)\n",
    "\n",
    "    ax.axhline(0, xmin=0, xmax=1,\n",
    "               color='gray', alpha=.3, zorder=0,)\n",
    "    if PLOT_CORR: ylines = [-4, -2, 2, 4,]\n",
    "    else: ylines = [1, 3, 5, 7, 9]\n",
    "    for yline in ylines:\n",
    "        ax.axhline(yline, xmin=0, xmax=1, color='gray', alpha=.15, zorder=0,)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(os.path.join(load_utils.get_onedrive_path('figures'),\n",
    "#              'ema_naturalistic', fname),\n",
    "#              dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check completion rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for rec_moment in data.keys():\n",
    "\n",
    "    for sub in data[rec_moment].keys():\n",
    "\n",
    "        df = data[rec_moment][sub]\n",
    "\n",
    "        df['Submission'] = pd.to_numeric(df['Submission'], errors='coerce')\n",
    "        rate = df['Submission'].mean()\n",
    "        print(f\"{sub} completion rate @ {rec_moment}: {rate:.0%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-analysis paper: EMA pre-post vs UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.mixed_linear_model import MixedLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_SEL = 'general movement'\n",
    "\n",
    "PER1 = 'pre-op'\n",
    "PER2 = 'post 3MFU'\n",
    "\n",
    "pt_pre = list(data[PER1].keys())\n",
    "pt_sel = [p for p in list(data[PER2].keys()) if p in pt_pre]\n",
    "\n",
    "stat_df = {'sub': [], 'period': [], 'ema': []}\n",
    "\n",
    "pt_coding = {}\n",
    "\n",
    "for i_pt, pt in enumerate(pt_sel):  # add index for pt coding\n",
    "    pt_coding[pt] = i_pt\n",
    "    for i_period, period in enumerate([PER1, PER2]):\n",
    "        values = data[period][pt]\n",
    "        values = values.loc[values['Submission'].astype(int) == 1]  # only take completed emas\n",
    "        values = values[Q_SEL].astype(float)  # take selected question\n",
    "        values = values[~np.isnan(values)]  # excl nan values\n",
    "        stat_df['ema'].extend(values)\n",
    "        stat_df['sub'].extend([i_pt] * len(values))\n",
    "        stat_df['period'].extend([i_period] * len(values))\n",
    "\n",
    "stat_df = pd.DataFrame(stat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt in np.unique(stat_df['sub']):\n",
    "\n",
    "    temp_df = stat_df[stat_df['sub'] == pt]\n",
    "    values = [temp_df[temp_df['period'] == p]['ema'] for p in [0, 1]]\n",
    "    plt.boxplot(values)\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### stats\n",
    "\n",
    "# define model\n",
    "lm_model = MixedLM(\n",
    "    endog=np.array(stat_df['period']),  # dependent variable \n",
    "    exog=np.array(stat_df['ema']),  # independent variable (i.e., LID presence, movement)\n",
    "    groups=np.array(stat_df['sub']),  # subjects\n",
    "    exog_re=None,  # (None)  defaults to a random intercept for each group\n",
    ")\n",
    "# run and fit model\n",
    "# try:\n",
    "lm_results = lm_model.fit()\n",
    "# except:\n",
    "#     if allow_lm_error:\n",
    "#         return False\n",
    "#     else:\n",
    "#         print(dep_var.shape, indep_var.shape, groups.shape)\n",
    "#         lm_results = lm_model.fit()\n",
    "\n",
    "# extract results\n",
    "fixeff_cf = lm_results._results.fe_params[0]\n",
    "pval = lm_results._results.pvalues[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_results._results.fe_params, lm_results._results.pvalues\n",
    "\n",
    "print(lm_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check means and variances for movement items, tremor, and gait items\n",
    "- split per sub\n",
    "- split per ses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.EMA_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(home_helpers)\n",
    "\n",
    "data = {}\n",
    "\n",
    "# Define pre-operative sessions\n",
    "sel_info = home_helpers.select_sessions()\n",
    "sel_info = sel_info.set_index(sel_info['study_id'],)\n",
    "sel_sessions = {sub: ses for sub, ses in sel_info[['study_id', 'Session']].values}\n",
    "print(sel_sessions)\n",
    "\n",
    "\n",
    "for sub, ses in sel_sessions.items():\n",
    "\n",
    "    data[sub] = loadSubject(\n",
    "        sub=sub,\n",
    "        ses=ses,\n",
    "        incl_EMA=True,\n",
    "        incl_ACC=False,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore naturalistic ACC\n",
    "\n",
    "include loading option for ACC only for EMA windows, store these selected windows separately, to prevent loading of full acc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_data_path = os.path.join(\n",
    "    os.path.dirname(load_utils.get_onedrive_path()),\n",
    "    'PROJECTS', 'home_feasibility'\n",
    ")\n",
    "feas_fig_path = os.path.join(\n",
    "    load_utils.get_onedrive_path('figures'),\n",
    "    'feasibility'\n",
    ")\n",
    "\n",
    "ntrl_fig_path = load_utils.get_onedrive_path('emaval_fig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ACC data, create SVM and filtered data wihtin the dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbs_home.preprocessing import acc_preprocessing as acc_prep\n",
    "from dbs_home.preprocessing import get_submovements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import naturalistic data via dbs_home repo\n",
    "\n",
    "# LID\n",
    "sub_id = 'hm24'\n",
    "ses_id = 'ses01'\n",
    "\n",
    "# # tremor check for Anna\n",
    "# sub_id = 'hm22'\n",
    "# ses_id = 'ses01'\n",
    "\n",
    "### test days for hm24-ses01  # dyskinesia\n",
    "# dev_day_selection = ['2025-07-17', '2025-07-18']\n",
    "# dev_day_selection = [f'2025-07-{d}' for d in np.arange(17, 31)]\n",
    "dev_day_selection = []\n",
    "\n",
    "### test days for hm20-ses01  # tremor\n",
    "# dev_day_selection = [\n",
    "#     '2025-06-13', '2025-06-14',\n",
    "#     '2025-06-15', '2025-06-16'\n",
    "# ]\n",
    "\n",
    "home_dat = loadSubject(\n",
    "    sub=sub_id,\n",
    "    ses=ses_id,\n",
    "    incl_STEPS=False,\n",
    "    incl_EPHYS=False,\n",
    "    incl_EMA=True,\n",
    "    incl_ACC=True,\n",
    "    day_selection=dev_day_selection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check available EMAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_home_compl.plot_EMA_completion_perSession(home_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Acc-Windows aligned to EMAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass(init=True,)\n",
    "class windowData:\n",
    "    sub: str\n",
    "    ses: str\n",
    "    day: str | None = None\n",
    "    acc_times: np.ndarray | None = None\n",
    "    acc_triax: np.ndarray | None = None\n",
    "    acc_svm: np.ndarray | None = None\n",
    "    sfreq: int | None = None\n",
    "    ema: dict = field(default_factory=dict)\n",
    "    day: str | None = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "\n",
    "        print(f'created windowData class for {self.sub}, {self.ses};'\n",
    "              f'starttime {self.acc_times[0]}')\n",
    "        if type(self.day) == str: print(f'belonging to day {self.day}')\n",
    "\n",
    "        if self.sfreq == None:\n",
    "            # extract sfreq if not given\n",
    "            time_df = np.diff(self.acc_times[:5])[0]\n",
    "            self.sfreq = int(dt.timedelta(seconds=1) / time_df)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submove_day_timestamps(\n",
    "    day, sub, ses, SM_MIN_DUR=0, SM_MAX_DUR=60,\n",
    "    SUBMOVE_version='v1',\n",
    "):\n",
    "\n",
    "    sm_day_times = get_submovements.load_submovements(\n",
    "        sub_id=sub, ses_id=ses, day=day,\n",
    "        ONLY_TIMES=True, SUBMOVE_version=SUBMOVE_version,\n",
    "    )\n",
    "\n",
    "    # get submovement start and ends (from json-dict)\n",
    "    sm_time_arr = np.array([list(s.values()) for s in sm_day_times['submovements']])\n",
    "    # get array with datetime objects for starts and ends\n",
    "    sm_day_starts = np.array([dt.datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "                            for t in sm_time_arr[:, 0]])\n",
    "    sm_day_ends = np.array([dt.datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "                        for t in sm_time_arr[:, 1]])\n",
    "    \n",
    "    sm_durations = sm_day_ends - sm_day_starts\n",
    "    sel_submoves = np.logical_and(\n",
    "        sm_durations > dt.timedelta(seconds=SM_MIN_DUR),\n",
    "        sm_durations < dt.timedelta(seconds=SM_MAX_DUR),\n",
    "    )\n",
    "    sm_day_starts = sm_day_starts[sel_submoves]\n",
    "    sm_day_ends = sm_day_ends[sel_submoves]\n",
    "    \n",
    "    return sm_day_starts, sm_day_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_submoveMask(win_times, sm_dt_starts, sm_dt_ends,):\n",
    "    \"\"\"\n",
    "    get boolean array that is \"1\" for submovement-positive samples\n",
    "    during EMA-window-matched acc data\n",
    "\n",
    "    returns:\n",
    "    - array with shape acc-window, positive for submove samples\n",
    "    - boolean array for day-submoves that are within current window-times\n",
    "    \"\"\"\n",
    "\n",
    "    # get start and end time of acc-ema window\n",
    "    win_start, win_end = win_times[0], win_times[-1]\n",
    "\n",
    "    # compare and select starts and ends within acc-ema-window\n",
    "    submoves_in_win_mask = np.logical_and(\n",
    "        sm_dt_starts > win_start,\n",
    "        sm_dt_ends < win_end\n",
    "    )\n",
    "    win_sm_starts = sm_dt_starts[submoves_in_win_mask]\n",
    "    win_sm_ends = sm_dt_ends[submoves_in_win_mask]\n",
    "\n",
    "    # select window-samples that are within submoves\n",
    "    # create boolean for acc-window, that will be 1 during submoves\n",
    "    win_submove_bool = np.zeros_like(win_times)\n",
    "    for t1, t2 in zip(win_sm_starts, win_sm_ends):\n",
    "        mask = np.logical_and(win_times > t1, win_times < t2)\n",
    "        win_submove_bool[mask] = 1\n",
    "\n",
    "    win_submove_bool = win_submove_bool.astype(bool)\n",
    "\n",
    "    return win_submove_bool, submoves_in_win_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "from scipy.stats import variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempwin = sm_win_data[5]\n",
    "\n",
    "print(vars(tempwin).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thoughts: velocity is negative?\n",
    "# pc's exclude, many of the variance within the acc signal\n",
    "\n",
    "for i_sm, tempwin in enumerate(sm_win_data[:30]):\n",
    "\n",
    "    for att in ['pc1', 'pc2']:\n",
    "        plt.plot(tempwin.timestamps, getattr(tempwin, att), label=att,\n",
    "                lw=3, alpha=.5,)\n",
    "\n",
    "    plt.plot(tempwin.timestamps, tempwin.svm, label='svm',)\n",
    "    plt.plot(tempwin.timestamps, tempwin.velocity.T,\n",
    "            label=[f'velo_{a}' for a in 'xyz'],\n",
    "            ls='--',)\n",
    "\n",
    "    plt.title(f'submovement # {i_sm}')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# microsecs = np.array([t.microsecond for t in tempwin.timestamps]) * 1e-6\n",
    "# microsecs = np.array([t.microsecond for t in tempwin.timestamps])\n",
    "\n",
    "plt.plot(tempwin.velocity.T)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "projected = pca.fit_transform(tempwin.velocity.T)  # Shape: (N, 2)\n",
    "\n",
    "pc1 = projected[:, 0]  # Primary direction\n",
    "pc2 = projected[:, 1]  # Secondary direction\n",
    "\n",
    "plt.plot(pc1, alpha=.3, lw=5,)\n",
    "plt.plot(pc2, alpha=.3, lw=5,)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.abs(tempwin.velocity.T))\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "projected = pca.fit_transform(np.abs(tempwin.velocity.T))  # Shape: (N, 2)\n",
    "\n",
    "pc1 = projected[:, 0]  # Primary direction\n",
    "pc2 = projected[:, 1]  # Secondary direction\n",
    "\n",
    "plt.plot(pc1, alpha=.3, lw=5,)\n",
    "plt.plot(pc2, alpha=.3, lw=5,)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbs_home.preprocessing.submovement_processing as submove_proc\n",
    "import dbs_home.load_raw.load_watch_raw as load_watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_watch)\n",
    "\n",
    "hr_day_data = load_watch.get_source_heartrate_day(\n",
    "    sub=home_dat.sub, ses=home_dat.ses, date='2025-08-13',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = windat.acc_times[0]\n",
    "t2 = windat.acc_times[-1]\n",
    "\n",
    "hr_sel = np.logical_and(hr_day_data['timestamp'] > t1,\n",
    "                        hr_day_data['timestamp'] < t2)\n",
    "\n",
    "hr_win = hr_day_data[hr_sel].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "hr_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax.plot(windat.acc_times, windat.acc_svm)\n",
    "ax2.plot(hr_win['timestamp'], hr_win[' HeartRate'], color='orangered',)\n",
    "\n",
    "ax2.plot(hr_day_data['timestamp'], hr_day_data[' HeartRate'],\n",
    "         color='orangered',)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_submove_check(\n",
    "    FIGDIR, FIGNAME, SAVE_PLOT, SHOW_PLOT,\n",
    "    windat, win_submove_bool, ema_win, hr_win,\n",
    "    str_day, i_win, SUBMOVE_version,\n",
    "):\n",
    "\n",
    "    FONTSIZE = 12\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(hr_win['timestamp'], hr_win[' HeartRate'], color='orangered',)\n",
    "    ax2.set_ylim(-10, 130)\n",
    "    ax2.set_ylabel('Heartrate (bpm)', size=FONTSIZE, color='orangered')\n",
    "\n",
    "    ax.plot(windat.acc_times, windat.acc_svm, label='svm', alpha=.5,)\n",
    "    ax.scatter(windat.acc_times, win_submove_bool.astype(int),\n",
    "                label='submove-boolean', s=50, alpha=.3, color='orange',)\n",
    "    ax.set_ylim(-.5, 5)\n",
    "    ax.set_ylabel('ACC-vector (squared-magn.)',\n",
    "                    size=FONTSIZE, color='blue')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title(\n",
    "        f'{str_day}: EMA-window # {i_win} ({windat.sub}, {windat.ses}, submove-{SUBMOVE_version})'\n",
    "        f'\\n EMA: tremor: {ema_win[\"Q7\"]}, dyskinesia: {ema_win[\"Q8\"]}'\n",
    "    )\n",
    "\n",
    "    for axx in [ax, ax2]:\n",
    "        axx.tick_params(axis='both', size=FONTSIZE,\n",
    "                        labelsize=FONTSIZE,)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVE_PLOT:\n",
    "        plt.savefig(os.path.join(FIGDIR, FIGNAME), facecolor='w', dpi=150,)\n",
    "\n",
    "    if SHOW_PLOT: plt.show()\n",
    "    else: plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(get_submovements)\n",
    "importlib.reload(submove_proc)\n",
    "\n",
    "\n",
    "SELECT_SUBMOVES = False\n",
    "EXTRACT_FT_FROM_SMs = True\n",
    "assert not SELECT_SUBMOVES and EXTRACT_FT_FROM_SMs, (\n",
    "    'CHOSE ONE OF TWO APROACHES, data OR times from submoves'\n",
    ")\n",
    "\n",
    "SUBMOVE_version = 'v3'\n",
    "ACC_SFREQ = 32\n",
    "ACC_MIN_PER_EMA = 15\n",
    "\n",
    "SM_MIN_DUR = .5  # sec\n",
    "SM_MAX_DUR = 600  # sec\n",
    "\n",
    "MIN_ACC_PRESENT = 0.5\n",
    "WIN_SAMPLES = (ACC_MIN_PER_EMA * 60 * ACC_SFREQ)\n",
    "\n",
    "# plotting settings\n",
    "SAVE_PLOT = False\n",
    "SHOW_PLOT = False\n",
    "FIGDIR = os.path.join(\n",
    "    home_helpers.finding_paths.get_home_onedrive('figures'),\n",
    "    'acc_processing', 'submovement_checks',\n",
    "    f'submove_{SUBMOVE_version}', windat.sub, windat.ses\n",
    ")\n",
    "if not os.path.exists(FIGDIR): os.makedirs(FIGDIR)\n",
    "\n",
    "### ft extraction params\n",
    "FEATS_INCL: ['hr_mean', 'hr_std', 'hr_cfvar',]\n",
    "\n",
    "# if features are not directly extraced, list to store data\n",
    "if EXTRACT_FT_FROM_SMs:\n",
    "    FEAT_STORE = {f: [] for f in FEATS_INCL}\n",
    "else:\n",
    "    all_windows = []\n",
    "\n",
    "for i_day, str_day in enumerate(home_dat.watch_days):\n",
    "    # define current day\n",
    "    print(f\"\\n\\n##### START day: {str_day}\")\n",
    "    # get dict for current day, needed in both methods of ft extraction (sm or not sm)\n",
    "    day_dict_lists = acc_prep.get_day_EMA_AccWindows(\n",
    "        subSesClass=home_dat, str_day=str_day,\n",
    "    )\n",
    "    \n",
    "    if not EXTRACT_FT_FROM_SMs:\n",
    "\n",
    "        if SELECT_SUBMOVES:\n",
    "            (sm_day_starts,\n",
    "             sm_day_ends) = get_submove_day_timestamps(\n",
    "                str_day, home_dat.sub, home_dat.ses,\n",
    "                SM_MIN_DUR=SM_MIN_DUR, SM_MAX_DUR=SM_MAX_DUR,\n",
    "                SUBMOVE_version=SUBMOVE_version,\n",
    "            )\n",
    "        \n",
    "    else:\n",
    "        # extract feats from sm-data directly\n",
    "        sm_day_data = get_submovements.load_submovements(\n",
    "            sub_id=sub_id, ses_id=ses_id, day=str_day,\n",
    "            ONLY_TIMES=False,\n",
    "            SUBMOVE_version=SUBMOVE_version,\n",
    "        )\n",
    "        # select submoves on durations\n",
    "        sm_day_data = [s for s in sm_day_data\n",
    "                       if np.logical_and(s.duration > SM_MIN_DUR,\n",
    "                                         s.duration < SM_MAX_DUR)]\n",
    "        # get sm times for selection within window\n",
    "        (sm_day_starts,\n",
    "         sm_day_ends) = get_submove_day_timestamps(\n",
    "            str_day, home_dat.sub, home_dat.ses,\n",
    "            SM_MIN_DUR=SM_MIN_DUR, SM_MAX_DUR=SM_MAX_DUR,\n",
    "            SUBMOVE_version=SUBMOVE_version,\n",
    "        )\n",
    "    \n",
    "    # load heartrate for full day\n",
    "    hr_day_data = load_watch.get_source_heartrate_day(\n",
    "        sub=home_dat.sub, ses=home_dat.ses, date=str_day,\n",
    "    )\n",
    "\n",
    "\n",
    "    for i_win in np.arange(len(list(day_dict_lists.values())[0])):\n",
    "\n",
    "        print(f\"\\n\\n\\n######## START day-win # {i_win} / {len(list(day_dict_lists.values())[0])}\")\n",
    "\n",
    "        # create class with processed acc-data and with ema-dict per completed ema\n",
    "        \n",
    "        # skip incomplete acc data\n",
    "        if len(day_dict_lists['acc_times'][i_win]) < (WIN_SAMPLES * MIN_ACC_PRESENT):\n",
    "            print(f\"skip WIN, not enough acc-data \"\n",
    "                  f\"({len(day_dict_lists['acc_times'][i_win]) / (60 * ACC_SFREQ)} minutes)\")\n",
    "            continue\n",
    "\n",
    "        # check for missing EMA data, and skip emas with missings\n",
    "        if any(day_dict_lists['ema'][i_win].values == ''):\n",
    "            print('skip WIN, missing EMA')\n",
    "            continue\n",
    "    \n",
    "        # get window data\n",
    "        windat = windowData(\n",
    "            sub=home_dat.sub,\n",
    "            ses=home_dat.ses,\n",
    "            day=str_day,\n",
    "            acc_times=day_dict_lists['acc_times'][i_win],\n",
    "            acc_triax=day_dict_lists['acc_filt'][i_win],\n",
    "            acc_svm=day_dict_lists['acc_svm'][i_win],\n",
    "            ema=day_dict_lists['ema'][i_win],\n",
    "        )\n",
    "\n",
    "        # select heartrate for current window\n",
    "        t1 = windat.acc_times[0]\n",
    "        t2 = windat.acc_times[-1]\n",
    "        hr_sel = np.logical_and(hr_day_data['timestamp'] > t1,\n",
    "                                hr_day_data['timestamp'] < t2)\n",
    "        hr_win = hr_day_data[hr_sel].reset_index(drop=True)\n",
    "\n",
    "        # store window data for later ft-extraction\n",
    "        if not EXTRACT_FT_FROM_SMs:\n",
    "            if SELECT_SUBMOVES:\n",
    "                # get mask for submove-pos samples in window\n",
    "                win_submove_bool = get_window_submoveMask(\n",
    "                    windat.acc_times, sm_day_starts, sm_day_ends,\n",
    "                )\n",
    "                print(f'\\nsubmove-positive window selection is '\n",
    "                      f'{round(sum(win_submove_bool) / len(win_submove_bool) * 100)}%')\n",
    "                # change timeseries-attributes within window class\n",
    "                for att in ['acc_times', 'acc_svm', 'acc_triax']:\n",
    "                    full_series = getattr(windat, att)\n",
    "                    setattr(windat, att, full_series[win_submove_bool])\n",
    "                \n",
    "                # store durations of single selected submoves within window\n",
    "                sm_durations = sm_day_ends[win_submove_bool] - sm_day_starts[win_submove_bool]\n",
    "                setattr(windat, 'sm_durations', sm_durations)\n",
    "\n",
    "            all_windows.append(windat)\n",
    "\n",
    "        # EXTRACT FEATURES directly, without substoring\n",
    "        else:\n",
    "            # EXTRACT FEATS FROM SUBMOVES DIRECTLY, no sub storing\n",
    "            ema_win = day_dict_lists['ema'][i_win]\n",
    "            \n",
    "            # get mask for submove-pos samples in window\n",
    "            win_submove_bool, submoves_in_win_bool = get_window_submoveMask(\n",
    "                windat.acc_times, sm_day_starts, sm_day_ends,\n",
    "            )            \n",
    "\n",
    "            # merges all submoves within EMA window -> \n",
    "            print(f'\\nsubmove-positive window selection is '\n",
    "                  f'{round(sum(win_submove_bool)/len(win_submove_bool)*100)}%')\n",
    "\n",
    "            # only submoves from day, are within current window\n",
    "            sm_win_data = list(compress(sm_day_data, submoves_in_win_bool))\n",
    "\n",
    "            print(f'n-submovements in window: {len(sm_win_data)}')\n",
    "            win_sm_mean = np.mean([s.duration for s in sm_win_data]).round(2)\n",
    "            win_sm_var = np.var([s.duration for s in sm_win_data]).round(2)\n",
    "            win_sm_cfvar = variation([s.duration for s in sm_win_data]).round(2)\n",
    "            print(f'durations: mean {win_sm_mean}, var {win_sm_var}, coef-var {win_sm_cfvar}')\n",
    "\n",
    "            # check correctness of submovements by plotting window ACC\n",
    "            if SAVE_PLOT or SHOW_PLOT:\n",
    "                FIGNAME = f'submoveCheck_{SUBMOVE_version}_{windat.sub}_{windat.ses}_{str_day}_ema{i_win}'\n",
    "                plot_submove_check(\n",
    "                    FIGDIR=FIGDIR, FIGNAME=FIGNAME, SAVE_PLOT=SAVE_PLOT,\n",
    "                    SHOW_PLOT=SHOW_PLOT, SUBMOVE_version=SUBMOVE_version,\n",
    "                    windat=windat, win_submove_bool=win_submove_bool,\n",
    "                    ema_win=ema_win, str_day=str_day,i_win=i_win, hr_win=hr_win,\n",
    "                )\n",
    "\n",
    "            # TODO: EXTRACT FEATURES HERE FROM SUBMOVE data\n",
    "\n",
    "            ### acc-features from full window\n",
    "\n",
    "\n",
    "            ### acc-features from sub-moves\n",
    "\n",
    "            # TODO: try for cnn -> interpolate sm-features into \n",
    "            # n=100 (zB) mask, 0-padding for n-sm <100 windows\n",
    "        \n",
    "            ### heartrate features\n",
    "            hr = [h if not h==0 else np.nan for h in hr_win[' HeartRate'].values]\n",
    "            \n",
    "            if 'hr_mean' in FEATS_INCL:\n",
    "                hr_mean = np.nanmean(hr)\n",
    "                if not np.isnan(hr_mean): FEAT_STORE['hr_mean'].append(hr_mean)\n",
    "                else: FEAT_STORE['hr_mean'].append(0)\n",
    "            if 'hr_std' in FEATS_INCL:\n",
    "                hr_std = np.nanstd(hr)\n",
    "                if not np.isnan(hr_std): FEAT_STORE['hr_mean'].append(hr_std)\n",
    "                else: FEAT_STORE['hr_std'].append(0)\n",
    "            if 'hr_cfvar' in FEATS_INCL:\n",
    "                hr_cfvar = variation(hr)\n",
    "                if not np.isnan(hr_cfvar): FEAT_STORE['hr_cfvar'].append(hr_cfvar)\n",
    "                else: FEAT_STORE['hr_cfvar'].append(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.nanmean([h if not h==0 else np.nan for h in hr_win[' HeartRate'].values]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in case later necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_datetime(t, T_RES_Sec = .1):\n",
    "    \"\"\"rounds on 0.1 sec\"\"\"\n",
    "\n",
    "    t_sec = t.microsecond / 1e6\n",
    "    t_sec_round = round(t_sec, abs(np.log10(T_RES_Sec)).astype(int))\n",
    "    micro = t_sec_round * 1e6\n",
    "\n",
    "    # add full second if rounding goes to 1e6 microseconds\n",
    "    if micro == 1e6:\n",
    "        t = t.replace(microsecond=0)\n",
    "        t += dt.timedelta(seconds=1)\n",
    "    # else replace rounded microseconds\n",
    "    else:\n",
    "        t = t.replace(microsecond=int(micro))\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature extractions, TODO: extract features from only submovements\n",
    "\n",
    "- Hssayeni et al, Scientific Reports 2021\n",
    "    - strongest wrist-features: angular velocity, standard deviation, power of secondary frequency, power of 1â€“4 Hz band, and Shannon Entropy (r = 0.82  - r = 0.75)\n",
    "    \n",
    "- from svm: classic features\n",
    "- include cross-corr between pc1 and pc2\n",
    "- correct necessary 'sum' features for the submove-lengths\n",
    "\n",
    "Include submovement descriptives as features per windows\n",
    "- n submovements / min\n",
    "- mean length\n",
    "- variation of lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "from scipy.stats import variation, pearsonr, spearmanr\n",
    "from scipy.signal import welch, find_peaks\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import utils.acc_features as acc_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(acc_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_features(\n",
    "    segData,\n",
    "    incl_feats: list = field(default_factory=[]),    \n",
    "):\n",
    "\n",
    "    # prepare psd in case spectral features inclued\n",
    "    if any(['pow' in f or 'freq' in f for f in incl_feats]):\n",
    "        (segData.fx, segData.psx) = acc_fts.get_psd(segData)\n",
    "    \n",
    "    seg_feats = []\n",
    "\n",
    "    for ft in [ft for ft, sel in incl_feats.items() if sel]:\n",
    "        value = getattr(acc_fts, f'get_{ft}')(segData)\n",
    "        seg_feats.append(value)\n",
    "    \n",
    "    return seg_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats_for_window(\n",
    "    windatClass,\n",
    "    SEG_LEN_SEC: float = 1,\n",
    "    FEATS_INCL: dict = {\n",
    "        'svm_rms': True, 'jerk_magn': True,\n",
    "        'svm_sd': True, 'svm_var': True,\n",
    "        'ax_var': True, 'pow_1_4': True,\n",
    "        'pow_4_8': True, 'pow_2ndFreq': True,\n",
    "        'corrcoef_components': True,\n",
    "    },\n",
    "    featClass = None,\n",
    "    SUMMARY_METH = None,\n",
    "):\n",
    "    \n",
    "    if type(SUMMARY_METH) == str:\n",
    "        assert(SUMMARY_METH in ['mean', 'std', '90perc']), 'INCORRECT SUMM METHOD'\n",
    "\n",
    "    # extract segment length if not given\n",
    "    SEG_N_SAMPLES = SEG_LEN_SEC * windatClass.sfreq\n",
    "\n",
    "    win_feats = []  # for arr structure\n",
    "    sel_feats = [ft for ft, bl in FEATS_INCL.items() if bl == True]\n",
    "    # print(win_feats)\n",
    "\n",
    "    # calculate features per segment\n",
    "    segClass = dataclasses.replace(windatClass)\n",
    "\n",
    "    for i_start in np.arange(len(windatClass.acc_svm) - SEG_N_SAMPLES,\n",
    "                             step=SEG_N_SAMPLES):\n",
    "        \n",
    "        i_end = i_start + SEG_N_SAMPLES\n",
    "        # print(f'SEGMENT indices:', i_start, i_end)\n",
    "        for att in ['acc_times', 'acc_svm', 'acc_triax']:\n",
    "            setattr(segClass, att, getattr(windatClass, att)[i_start:i_end])\n",
    "            # print(f'shape {att}: {getattr(segClass, att).shape}')\n",
    "        seg_fts = get_segment_features(segData=segClass,\n",
    "                                       incl_feats=FEATS_INCL)\n",
    "        # add all feats per segment\n",
    "        win_feats.append(seg_fts)\n",
    "    \n",
    "    win_feats = np.array(win_feats)  # return values as one array\n",
    "        \n",
    "    if type(SUMMARY_METH) == str:\n",
    "        if SUMMARY_METH == 'mean':\n",
    "            win_feats = np.mean(win_feats, axis=0,)\n",
    "        elif SUMMARY_METH == 'std':\n",
    "            win_feats = np.std(win_feats, axis=0,)\n",
    "        elif SUMMARY_METH == '90perc':\n",
    "            win_feats = np.percentile(win_feats, 90, axis=0,)\n",
    "\n",
    "\n",
    "    return win_feats, sel_feats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "vars(windat).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "trems = np.array([int(w.ema['Q7']) for w in all_windows])\n",
    "dys = np.array([int(w.ema['Q8']) for w in all_windows])\n",
    "\n",
    "EMA_Y = np.mean([trems, dys], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "STAT, p = spearmanr(trems, dys)\n",
    "print(f'LID and tremor correlation: {STAT.round(2)}, p={p.round(5)}')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "ax.scatter(trems + np.random.uniform(-.2, .2, len(trems)),\n",
    "            dys + np.random.uniform(-.2, .2, len(dys)))\n",
    "ax.set_xlabel('Tremor')\n",
    "ax.set_ylabel('LID')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "ax.plot(trems, color='green', label='tremor',)\n",
    "ax.plot(dys, color='pink', label='lid')\n",
    "ax.plot(np.mean([trems, dys], axis=0), color='orange', lw=5, alpha=.5, label='mean')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(acc_fts)\n",
    "\n",
    "\n",
    "FEATS_INCL = {\n",
    "    'jerk_magn': True,\n",
    "    'svm_sd': True,\n",
    "    'svm_var': True,\n",
    "    'pow_1_4': True,\n",
    "    'pow_4_8': True, \n",
    "    'pow_2ndFreq': True,\n",
    "    'corrcoef_components': True,\n",
    "}\n",
    "\n",
    "EMA_TARGET = 'Q8'  # dyskinesia\n",
    "EMA_CONF = 'Q7'  # tremor\n",
    "\n",
    "EXCL_CONFOUNDERS = False\n",
    "CONF_CUT = 5\n",
    "\n",
    "### create X-array with features per window\n",
    "X_lists, y_lists = [], []\n",
    "conf_list = []\n",
    "day_list = []  # for grouping random variables\n",
    "\n",
    "for i_win, windat in enumerate(all_windows):\n",
    "    \n",
    "    print(f'start # {i_win+1} / {len(all_windows)}')\n",
    "\n",
    "    if len(windat.acc_times) < windat.sfreq:\n",
    "        print(f'\\n\\t##### SKIP window, data too short (n={len(windat.acc_times)})')\n",
    "        continue\n",
    "\n",
    "    ### create y-array with EMA-label per window\n",
    "    conf_value = float(windat.ema[EMA_CONF])\n",
    "    if EXCL_CONFOUNDERS:\n",
    "        if conf_value >= CONF_CUT: continue\n",
    "\n",
    "    conf_list.append(conf_value)\n",
    "    \n",
    "    y_lists.append(float(windat.ema[EMA_TARGET]))\n",
    "\n",
    "    tempfts, ft_keys = get_feats_for_window(\n",
    "        windatClass=windat,\n",
    "        FEATS_INCL=FEATS_INCL,\n",
    "        SUMMARY_METH='mean',  # 90perc, mean\n",
    "        SEG_LEN_SEC=1,\n",
    "    )\n",
    "\n",
    "    X_lists.append(tempfts)\n",
    "\n",
    "    # get day for later splitting\n",
    "    day_list.append(windat.day)\n",
    "\n",
    "# make arrays\n",
    "X_arr = np.array(X_lists)\n",
    "# # zscore\n",
    "# m, sd = np.mean(X_arr, axis=0), np.std(X_arr, axis=0)\n",
    "# X_arr[:, :] -= m\n",
    "# X_arr[:, :] /= sd\n",
    "\n",
    "y_arr = np.array(y_lists)\n",
    "# y_arr = EMA_Y  # mean tremor and lid\n",
    "conf_arr = np.array(conf_list)\n",
    "\n",
    "uniq_days = np.unique(day_list)\n",
    "day_codes = {str(d): i_day for i_day, d in enumerate(uniq_days)}\n",
    "daycode_arr = np.array([day_codes[d] for d in day_list])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualise features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_ft, ft in enumerate(ft_keys):\n",
    "\n",
    "    values = X_arr[:, i_ft]\n",
    "\n",
    "    plt.hist(values)\n",
    "    plt.title(ft)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_f, f in enumerate(ft_keys):\n",
    "    \n",
    "    values = X_arr[:, i_f]\n",
    "    values = (values - np.mean(values)) / np.std(values)\n",
    "\n",
    "    res = spearmanr(values, y_arr)\n",
    "\n",
    "    print(f'\\n{f}: {res.statistic.round(2)}, p = {res.pvalue.round(5)}')\n",
    "\n",
    "    plt.scatter(y_arr, X_arr[:, i_f])\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedLM(endog=y_arr, exog=X_arr, groups=daycode_arr)\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.fe_params\n",
    "\n",
    "result.cov_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, r2_score,\n",
    "    roc_auc_score, balanced_accuracy_score\n",
    ")\n",
    "from scipy.stats import f as stats_f\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import f_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_stat(y_pred, y_true, n_feats):\n",
    "    # F-statistic for model usability\n",
    "    \n",
    "    # Sum of squares\n",
    "    SSR = np.sum((y_pred - np.mean(y_true)) ** 2)   # Regression\n",
    "    SSE = np.sum((y_true - y_pred) ** 2)   # Error\n",
    "    SST = np.sum((y_true - np.mean(y_true)) ** 2)   # Total\n",
    "\n",
    "    # Degrees of freedom\n",
    "    df_reg = n_feats\n",
    "    df_err = len(y_true) - (n_feats + 1)  # +1 for coeff next to betas of features\n",
    "\n",
    "    # Mean squares\n",
    "    MSR = SSR / df_reg if df_reg > 0 else np.nan\n",
    "    MSE = SSE / df_err if df_err > 0 else np.nan\n",
    "    F = MSR / MSE\n",
    "    # p-value for the observed F\n",
    "    f_pval = 1 - stats_f.cdf(F, df_reg, df_err)\n",
    "\n",
    "    return F, f_pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proof of concept:\n",
    "- 1 sec segments\n",
    "- mean as averaging method\n",
    "- LDA for EMA prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'scale': LinearRegression(),\n",
    "          'lda': LDA(),\n",
    "          'bin': LogisticRegression()}\n",
    "\n",
    "\n",
    "CLSF = 'lda'\n",
    "\n",
    "# TEST_SEL = daycode_arr > 25  # takes circa .33\n",
    "\n",
    "# X_train = X_arr[~TEST_SEL, :]\n",
    "# y_train = y_arr[~TEST_SEL]\n",
    "\n",
    "# # test cohort\n",
    "# X_test = X_arr[TEST_SEL, :]\n",
    "# y_true = y_arr[TEST_SEL]\n",
    "\n",
    "\n",
    "# y_pred to fill (LOdayO)\n",
    "y_true = y_arr.astype(int)\n",
    "y_pred = np.zeros_like(y_true)\n",
    "\n",
    "# MAKE BINARY\n",
    "if CLSF == 'bin':\n",
    "    y_train = y_train >= 4\n",
    "    y_true = y_true >= 4\n",
    "\n",
    "# Run prediction\n",
    "\n",
    "# leave one day out CV\n",
    "for day in np.unique(daycode_arr):\n",
    "\n",
    "    TEST_SEL = daycode_arr == day\n",
    "    X_train = X_arr[~TEST_SEL, :]\n",
    "    y_train = y_arr.astype(int)[~TEST_SEL]\n",
    "\n",
    "    # test cohort\n",
    "    X_test = X_arr[TEST_SEL, :]\n",
    "\n",
    "    model = models[CLSF]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred[TEST_SEL] = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# round predictions to full numbers\n",
    "if CLSF == 'scale' or 'lda': \n",
    "    y_pred = np.array([np.round(v) for v in y_pred])\n",
    "\n",
    "    pred_F, pred_F_p = get_f_stat(y_pred=y_pred, y_true=y_true, n_feats=X_test.shape[1])\n",
    "    pred_corrcoef, prs_p = pearsonr(y_true, y_pred)\n",
    "    sk_f, sk_f_p = f_regression(y_pred.reshape(-1, 1), y_true)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    R2 = r2_score(y_true=y_true, y_pred=y_pred,)\n",
    "\n",
    "    print(f'({CLSF}) accuracy: {np.round(acc, 2)} (test sample: n={len(y_true)})')\n",
    "    print(f'({CLSF}) R2: {np.round(R2, 2)} (test sample: n={len(y_true)})')\n",
    "    print(f'({CLSF}) Corr-Coeff: {np.round(pred_corrcoef, 2)}, p={np.round(prs_p, 5)} (test sample: n={len(y_true)})')\n",
    "    print(f'({CLSF}) F-stat: {np.round(pred_F, 2)}, p={pred_F_p}')\n",
    "    print(f'({CLSF}) F-stat (sklearn): {np.round(sk_f, 2)}, p={np.round(sk_f_p, 5)}')\n",
    "\n",
    "\n",
    "elif  CLSF == 'bin':\n",
    "    auc = roc_auc_score(y_true=y_true, y_score=y_pred)\n",
    "    print(f'({CLSF}) AUROC: {np.round(auc, 2)} (test sample: n={len(y_true)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8, 3))\n",
    "\n",
    "ax.plot(y_true, color='orange', lw=5, alpha=.5,\n",
    "         label='true',)\n",
    "ax.plot(y_pred, color='purple', lw=2, alpha=.8,\n",
    "         label='predicted')\n",
    "\n",
    "ax.set_xlabel('Samples (n)', size=14)\n",
    "ax.set_ylabel('EMA LID value', size=14)\n",
    "ax.legend(frameon=False, fontsize=14, loc='upper right')\n",
    "\n",
    "ax.tick_params(axis='both', size=14, labelsize=14,)\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(os.path.join(load_utils.get_onedrive_path('figures'),\n",
    "#              'proof_kin_pred', 'LID_pred_hm24_ses01_24nov'),\n",
    "#              dpi=300, facecolor='w',)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "\n",
    "ax.scatter(y_true + np.random.uniform(-.2, .2, len(y_true)),\n",
    "            y_pred + np.random.uniform(-.2, .2, len(y_pred)),)\n",
    "ax.set_xlabel('true scores')\n",
    "ax.set_ylabel('predicted scores')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perm test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PERMS = 1000\n",
    "\n",
    "# TEST_SEL = daycode_arr > 20  # takes circa .33\n",
    "\n",
    "# X_train = X_arr[~TEST_SEL, :]\n",
    "# y_train = y_arr[~TEST_SEL]\n",
    "\n",
    "# # test cohort\n",
    "# X_test = X_arr[TEST_SEL, :]\n",
    "# y_true = y_arr[TEST_SEL]\n",
    "\n",
    "model = LDA()\n",
    "\n",
    "# Run prediction\n",
    "perm_mets ={'F': [], 'R': []}\n",
    "\n",
    "y_true = y_arr.astype(int)\n",
    "\n",
    "np.random.seed(27)\n",
    "\n",
    "for i_perm in np.arange(N_PERMS):\n",
    "\n",
    "    y_perm_pred = np.array([np.nan] * len(y_arr))\n",
    "\n",
    "    for day in np.unique(daycode_arr):\n",
    "\n",
    "        TEST_SEL = daycode_arr == day\n",
    "        X_train = X_arr[~TEST_SEL, :]\n",
    "        y_train = y_arr.astype(int)[~TEST_SEL]\n",
    "        np.random.shuffle(y_train)   \n",
    "\n",
    "        # test cohort\n",
    "        X_test = X_arr[TEST_SEL, :]\n",
    "\n",
    "        model = models[CLSF]\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_perm_pred[TEST_SEL] = model.predict(X_test)\n",
    "\n",
    "    # y_train = y_arr[~TEST_SEL]\n",
    "    # np.random.shuffle(y_train)   \n",
    "    # model.fit(X_train, y_train)\n",
    "\n",
    "    # y_perm_pred = model.predict(X_test)\n",
    "    # # np.random.shuffle(y_perm_pred)\n",
    "    y_perm_pred = np.array([np.round(v) for v in y_perm_pred])\n",
    "\n",
    "    F, f_pvalue = get_f_stat(y_pred=y_perm_pred, y_true=y_true,\n",
    "                             n_feats=X_test.shape[1])\n",
    "    prs_stat, _ = pearsonr(y_perm_pred, y_true)\n",
    "    perm_mets['F'].append(F)\n",
    "    perm_mets['R'].append(prs_stat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "pred_mets = {'F': pred_F, 'R': pred_corrcoef}\n",
    "\n",
    "for i_ax, metr in enumerate(list(perm_mets.keys())):\n",
    "\n",
    "    axes[i_ax].hist(perm_mets[metr], color='gray', alpha=.5,)\n",
    "    axes[i_ax].axvline(np.percentile(perm_mets[metr], 95),\n",
    "                       color='orange', alpha=.8, lw=3,\n",
    "                       label='permuted\\nalpha 0.05',)\n",
    "    \n",
    "    axes[i_ax].axvline(pred_mets[metr],\n",
    "                       color='purple', alpha=.5, lw=1,\n",
    "                       label='prediction',)\n",
    "    \n",
    "    p_calc = sum(pred_mets[metr] < perm_mets[metr]) / len(perm_mets[metr])\n",
    "    print(f'metric {metr}: p = {np.round(p_calc, 3)}')\n",
    "\n",
    "    axes[i_ax].set_xlabel(f'{metr} score', size=14,)\n",
    "\n",
    "    axes[i_ax].set_ylabel('count (n)', size=14)\n",
    "\n",
    "    axes[i_ax].tick_params(axis='both', size=14, labelsize=14,)\n",
    "    axes[i_ax].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "axes[1].legend(frameon=False, fontsize=14,\n",
    "               bbox_to_anchor=(.95, .5), loc='center left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(os.path.join(load_utils.get_onedrive_path('figures'),\n",
    "#              'proof_kin_pred', 'LID_pred_hm24_ses01_24nov_perms'),\n",
    "#              dpi=300, facecolor='w',)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
