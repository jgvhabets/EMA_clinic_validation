{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturalistic EMA validation\n",
    "\n",
    "Applying the findings from the 4-state correlation work (EMA x UPDRS) onto real-life EMA data.\n",
    "\n",
    "Goals:\n",
    "- analyse real-life variation of EMA values\n",
    "    - inter-individual variation\n",
    "    - intra-individual variation, daily fluctuations, differences between days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import packages\n",
    "\n",
    "- document versions for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import importlib\n",
    "from itertools import product, compress\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.signal import welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "# print('sci-py', scipy.__version__)\n",
    "# print('sci-kit learn', sk.__version__)\n",
    "# print('matplotlib', plt_version)\n",
    "\n",
    "\"\"\"\n",
    "Python sys 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
    "pandas 2.1.1\n",
    "numpy 1.26.0\n",
    "\n",
    "from 16.09\n",
    "\n",
    "Python sys 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
    "pandas 2.3.2\n",
    "numpy 2.3.3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbs_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from current repo\n",
    "from utils import load_utils, load_data, prep_data\n",
    "\n",
    "# from dbs_home repo\n",
    "import dbs_home.load_raw.main_load_raw as load_home\n",
    "import dbs_home.load_raw.load_watch_raw as load_watch\n",
    "import dbs_home.utils.helpers as home_helpers\n",
    "import dbs_home.utils.ema_utils as home_ema_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Home-Data\n",
    "\n",
    "Use pre-operative sessions\n",
    "\n",
    "- use 9-point-converter\n",
    "- use direct. inverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import EMA home data from raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTS = ['pre-op', 'pre 3MFU', 'post 3MFU']\n",
    "\n",
    "sub_skip = ['hm25',]\n",
    "ses_skip = [['hm14', 'ses03']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_include = {m: {} for m in MOMENTS}\n",
    "\n",
    "for rec_moment in MOMENTS:\n",
    "\n",
    "    sel_info = home_helpers.select_sessions(target_session=rec_moment)\n",
    "    sel_info = sel_info.set_index(sel_info['study_id'],)\n",
    "    sel_sessions = {sub: ses for sub, ses in sel_info[['study_id', 'Session']].values}\n",
    "\n",
    "    for key, val in sel_sessions.items():\n",
    "        sessions_include[rec_moment][key] = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data\n",
    "\n",
    "dev for EMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(home_ema_utils)\n",
    "importlib.reload(load_data)\n",
    "importlib.reload(prep_data)\n",
    "\n",
    "# load all combined data\n",
    "\n",
    "SUBS_INCL = ['hm14']\n",
    "\n",
    "\n",
    "data = {m: {} for m in MOMENTS}\n",
    "\n",
    "for rec_moment, sub_sess in sessions_include.items():\n",
    "\n",
    "    for sub, ses in sub_sess.items():\n",
    "\n",
    "        if sub in sub_skip: continue\n",
    "                    \n",
    "        if [sub, ses] in ses_skip: continue\n",
    "                \n",
    "        ses_class = load_home.loadSubject(\n",
    "            sub=sub,\n",
    "            ses=ses,\n",
    "            incl_EMA=True,\n",
    "            incl_ACC=False,\n",
    "        )\n",
    "        temp_df = home_ema_utils.load_ema_df(sub_ses_class=ses_class)\n",
    "        # prepare\n",
    "        temp_df = prep_data.prepare_ema_df(temp_df, ADD_MEANMOVE=True, INVERT_NEG_ITEMS=False,)\n",
    "        ### TODO: CHECK WHY NOT ALL SUBS ARE INVERTED PROPERLY\n",
    "\n",
    "        data[rec_moment][sub] = temp_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test different normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from data dict, different normalization means per subject, per item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())\n",
    "print(data['pre-op'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_colors(data):\n",
    "    \n",
    "    import matplotlib as mpl\n",
    "\n",
    "    allsubs = []\n",
    "    for mom in list(data.keys()): allsubs.extend(list(data[mom].keys()))\n",
    "    allsubs = np.unique(allsubs)\n",
    "\n",
    "    colors1 = list(mpl.colormaps['Set3'].colors)\n",
    "    colors2 = list(mpl.colormaps['Set2'].colors)\n",
    "    colors = colors1 + colors2\n",
    "\n",
    "    subcolors = {s: colors[i] for i, s in enumerate(allsubs)}\n",
    "\n",
    "    return subcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test answer ranges over different moments\n",
    "- test different normalizations:\n",
    "    - normalize with grand-mean per sub\n",
    "    - normalize with session mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_correct_ema_df(\n",
    "    df, CORR_METHOD: str = 'mean_over_all',\n",
    "    NUM_COLS = ['overall wellbeing', 'motivation', 'sadness',\n",
    "                'energy level', 'risky', 'general movement', \n",
    "                'tremor', 'dyskinesia', 'walking', 'hands', 'move_mean']):\n",
    "    \n",
    "    # mean correct\n",
    "    for col in NUM_COLS:\n",
    "        if CORR_METHOD == 'mean_over_all':\n",
    "            col_corr_m = np.nanmean(df[col])\n",
    "            df[f'{col}_corr'] = df[col] - col_corr_m\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sub_ema_df(datadict, sub: str):\n",
    "    \"\"\"\n",
    "    expect dict with MOMENTS-SUBS\n",
    "    \"\"\"\n",
    "    # df to store\n",
    "    df = None\n",
    "\n",
    "    # get all merged data per sub\n",
    "    for moment in list(datadict.keys()):\n",
    "\n",
    "        if sub in datadict[moment].keys():\n",
    "            tempdf = datadict[moment][sub]\n",
    "            # add column with moment origin\n",
    "            tempdf['moment'] = [moment] * tempdf.shape[0]\n",
    "        \n",
    "            # add dataframe to total\n",
    "            if type(df) != pd.DataFrame:\n",
    "                df = tempdf\n",
    "            else:\n",
    "                df = pd.concat([df, tempdf]).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess EMA\n",
    "\n",
    "- merge scores\n",
    "- invert negative-items (higher = clinically better)\n",
    "- mean-correct EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsubs = []\n",
    "for mom in list(data.keys()): allsubs.extend(list(data[mom].keys()))\n",
    "allsubs = np.unique(allsubs)\n",
    "\n",
    "\n",
    "corr_data = {m: {} for m in MOMENTS}\n",
    "\n",
    "for sub in allsubs:\n",
    "\n",
    "    subdf = merge_sub_ema_df(datadict=data, sub=sub)\n",
    "    subdf = mean_correct_ema_df(subdf)\n",
    "\n",
    "    # split and palce back as moment dfs    \n",
    "    for moment in MOMENTS:\n",
    "        corr_data[moment][sub] = subdf[subdf['moment'] == moment].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ITEMS = ['move_mean', 'walking', 'tremor']\n",
    "\n",
    "PLOT_CORR = True\n",
    "if PLOT_CORR: PLOT_DATADICT = corr_data\n",
    "else: PLOT_DATADICT = data\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 6))\n",
    "fname = 'motorItems_abs_perSub_perSes'\n",
    "if PLOT_CORR: fname = fname.replace('abs', 'corr')\n",
    "\n",
    "x_margin = 2\n",
    "bin_w = 0.5\n",
    "\n",
    "fsize=14\n",
    "\n",
    "x_starts = {list(data.keys())[0]: 0}  # first moment starts at 0\n",
    "\n",
    "subcolors = get_sub_colors(PLOT_DATADICT)\n",
    "\n",
    "\n",
    "for i_ax, col in enumerate(PLOT_ITEMS):\n",
    "\n",
    "    for i_mom, moment in enumerate(PLOT_DATADICT.keys()):\n",
    "\n",
    "        if PLOT_CORR and i_mom == 0: col = f'{col}_corr'\n",
    "\n",
    "        # loop over sub-dfs within moment and add specific column values\n",
    "        list_values = [tempdf[col].values for tempdf in PLOT_DATADICT[moment].values()]\n",
    "        box_subs = list(PLOT_DATADICT[moment].keys())  # subs included in this boxplot\n",
    "        # sort by sub id\n",
    "        i_sort = np.argsort(box_subs)\n",
    "        box_subs = [box_subs[i] for i in i_sort]\n",
    "        list_values = [list_values[i] for i in i_sort]\n",
    "\n",
    "        # drop NaN values in lists\n",
    "        list_values = [[v for v in l if not np.isnan(v)] for l in list_values]\n",
    "\n",
    "        # plot boxes for one moment\n",
    "        bp = axes[i_ax].boxplot(list_values, widths=bin_w,\n",
    "                           positions=x_starts[moment] + bin_w * np.arange(len(list_values)),\n",
    "                           patch_artist=True,)\n",
    "        if i_ax == 0:\n",
    "            if moment != list(PLOT_DATADICT.keys())[-1]:\n",
    "                x_starts[list(PLOT_DATADICT.keys())[i_mom + 1]] = x_starts[moment] + len(list_values) * bin_w + x_margin\n",
    "\n",
    "        # Loop over boxes\n",
    "        for patch, patchsub in zip(bp['boxes'], box_subs):\n",
    "            patch.set_facecolor(subcolors[patchsub])\n",
    "\n",
    "    # pretty plot\n",
    "    axes[i_ax].set_ylabel(f'{col}\\n(EMA answer)', size=fsize,)\n",
    "\n",
    "# pretty axes\n",
    "for ax in axes:\n",
    "    if not PLOT_CORR:\n",
    "        ax.set_ylim(0, 10)\n",
    "        ax.set_yticks(np.arange(1, 10, 2))\n",
    "        ax.set_yticklabels(np.arange(1, 10, 2))\n",
    "    else:\n",
    "        ax.set_ylim(-5, 5)\n",
    "        ax.set_yticks(np.arange(-4, 6, 2))\n",
    "        ax.set_yticklabels(np.arange(-4, 6, 2))\n",
    "\n",
    "    ax.set_xticks(list(x_starts.values()))\n",
    "    ax.set_xticklabels(list(x_starts.keys()))\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    ax.tick_params(axis='both', labelsize=fsize, size=fsize,)\n",
    "\n",
    "    ax.axhline(0, xmin=0, xmax=1,\n",
    "               color='gray', alpha=.3, zorder=0,)\n",
    "    if PLOT_CORR: ylines = [-4, -2, 2, 4,]\n",
    "    else: ylines = [1, 3, 5, 7, 9]\n",
    "    for yline in ylines:\n",
    "        ax.axhline(yline, xmin=0, xmax=1, color='gray', alpha=.15, zorder=0,)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(os.path.join(load_utils.get_onedrive_path('figures'),\n",
    "#              'ema_naturalistic', fname),\n",
    "#              dpi=300, facecolor='w',)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for rec_moment in data.keys():\n",
    "\n",
    "    for sub in data[rec_moment].keys():\n",
    "\n",
    "        df = data[rec_moment][sub]\n",
    "\n",
    "        df['Submission'] = pd.to_numeric(df['Submission'], errors='coerce')\n",
    "        rate = df['Submission'].mean()\n",
    "        print(f\"{sub} completion rate @ {rec_moment}: {rate:.0%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['3mfu']['hm13'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check means and variances for movement items, tremor, and gait items\n",
    "- split per sub\n",
    "- split per ses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.EMA_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(home_helpers)\n",
    "importlib.reload(load_home)\n",
    "\n",
    "data = {}\n",
    "\n",
    "# Define pre-operative sessions\n",
    "sel_info = home_helpers.select_sessions()\n",
    "sel_info = sel_info.set_index(sel_info['study_id'],)\n",
    "sel_sessions = {sub: ses for sub, ses in sel_info[['study_id', 'Session']].values}\n",
    "print(sel_sessions)\n",
    "\n",
    "\n",
    "for sub, ses in sel_sessions.items():\n",
    "\n",
    "    data[sub] = load_home.loadSubject(\n",
    "        sub=sub,\n",
    "        ses=ses,\n",
    "        incl_EMA=True,\n",
    "        incl_ACC=False,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['hm12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore ACC loading and completion\n",
    "\n",
    "\n",
    "include loading option for ACC only for EMA windows, store these selected windows separately, to prevent loading of full acc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_data)\n",
    "importlib.reload(prep_data)\n",
    "\n",
    "# load all combined data\n",
    "\n",
    "SUBS_INCL = ['hm14']\n",
    "\n",
    "\n",
    "emadata = {m: {} for m in MOMENTS}\n",
    "accdata = {m: {} for m in MOMENTS}\n",
    "\n",
    "for rec_moment, sub_sess in sessions_include.items():\n",
    "\n",
    "    for sub, ses in sub_sess.items():\n",
    "        print(f'\\n\\n{\"#\" * 30}\\nstart sub-{sub}: ses:{ses}\\n{\"#\" * 30}\\n\\n')\n",
    "\n",
    "        # to test acc loading\n",
    "        # if not sub in SUBS_INCL: continue\n",
    "\n",
    "        if sub in sub_skip: continue\n",
    "                    \n",
    "        if [sub, ses] in ses_skip: continue\n",
    "                \n",
    "        ses_class = load_home.loadSubject(\n",
    "            sub=sub,\n",
    "            ses=ses,\n",
    "            incl_EMA=True,\n",
    "            incl_ACC=True,\n",
    "        )\n",
    "        temp_df = ema_utils.load_ema_df(sub_ses_class=ses_class)\n",
    "        # prepare\n",
    "        temp_df = prep_data.prepare_ema_df(temp_df, ADD_MEANMOVE=True, INVERT_NEG_ITEMS=False,)\n",
    "        ### TODO: CHECK WHY NOT ALL SUBS ARE INVERTED PROPERLY\n",
    "\n",
    "        emadata[rec_moment][sub] = temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_watch)\n",
    "importlib.reload(load_home)\n",
    "importlib.reload(dbs_home)\n",
    "\n",
    "\n",
    "temp = load_home.loadSubject(\n",
    "            sub='hm23',\n",
    "            ses='ses01',\n",
    "            incl_EMA=True,\n",
    "            incl_ACC=True,\n",
    "            proc_ACC=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbs_home.utils.finding_paths as home_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explore feasbility, completion rates for acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(temp.acc_times[i_day][::(ACC_SFREQ * TIME_GAP_SEC)]))\n",
    "\n",
    "\n",
    "print(len(temp.acc_times[i_day][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate np.diff over timestamps\n",
    "TIME_GAP_SEC = 1\n",
    "ACC_SFREQ = 32\n",
    "\n",
    "sub_timesums = {}\n",
    "\n",
    "for i_day, day in enumerate(temp.watch_days):\n",
    "    print(f'\\n\\n{day}')\n",
    "    time_sum = dt.timedelta(0)  # store collected time sum in variable dt timedelta\n",
    "\n",
    "    time_diff = np.diff(temp.acc_times[i_day][::(ACC_SFREQ * TIME_GAP_SEC)])  # use every 1-second value\n",
    "\n",
    "    per_start, per_end = None, None\n",
    "\n",
    "    for t_df, stamp in zip(time_diff, temp.acc_times[i_day][::(ACC_SFREQ * TIME_GAP_SEC)]):  # loop over timedeltas\n",
    "\n",
    "        if not per_start:\n",
    "            per_start = stamp\n",
    "            # print(f'\\nstartis {per_start}')\n",
    "            continue\n",
    "\n",
    "        # if too large time gap\n",
    "        if t_df > dt.timedelta(seconds=TIME_GAP_SEC):\n",
    "            per_end = stamp\n",
    "            # print(f'end is {per_end}')\n",
    "\n",
    "            # add period times to list\n",
    "            # print(f'SUM pre: {time_sum}')\n",
    "            time_sum += (per_end - per_start)\n",
    "            # print(f'SUM post: {time_sum}')\n",
    "            # reset period times and start over\n",
    "            per_start, per_end = None, None\n",
    "\n",
    "    if per_start and not per_end:\n",
    "        per_end = stamp\n",
    "        print(f'END end is {per_end}')\n",
    "        print(f'last stamp is {temp.acc_times[i_day][-3:]}')\n",
    "        # add period times to list\n",
    "        print(f'SUM pre: {time_sum}')\n",
    "        time_sum += (per_end - per_start)\n",
    "        print(f'SUM post: {time_sum}')\n",
    "\n",
    "    # store day sum in sub dict\n",
    "    sub_timesums[day] = time_sum\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_data_path = os.path.join(\n",
    "    os.path.dirname(home_paths.get_home_onedrive()),\n",
    "    'PROJECTS', 'home_feasibility'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with highest protocol (fast & compact)\n",
    "fname = f\"acc_seconds_{temp.sub}_{temp.ses}.pkl\"\n",
    "with open(os.path.join(feas_data_path, fname), \"wb\") as f:\n",
    "    pickle.dump(sub_timesums, f,\n",
    "                protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load\n",
    "fname = f\"acc_seconds_{temp.sub}_{temp.ses}.pkl\"\n",
    "\n",
    "with open(os.path.join(feas_data_path, fname), \"rb\") as f:\n",
    "    feasload = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_fig_path = os.path.join(home_paths.get_home_onedrive('figures'), 'feasibility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'ACC_collection_{temp.sub}_{temp.ses}'\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 3))\n",
    "\n",
    "ax.bar(x=np.arange(len(sub_timesums)),\n",
    "       height=[t.seconds / 3600 for t in sub_timesums.values()])\n",
    "\n",
    "ax.set_xticklabels([l for l in sub_timesums.keys()],\n",
    "                   rotation=45,)\n",
    "ax.set_xticks(np.arange(len(sub_timesums.values())),\n",
    "              )\n",
    "ax.set_ylabel('Day sum (hours)')\n",
    "ax.set_title(f'collected ACC-time: {temp.sub}, {temp.ses}')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(feas_fig_path, fname), dpi=300,\n",
    "            facecolor='w', )\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess data: explore and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get (mean-corrected) EMA and UPDRS values per symptom subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_data)\n",
    "importlib.reload(prep_data)\n",
    "\n",
    "predat = ema_dat['hm14'].copy()\n",
    "# dat = prep_data.prepare_home_emas(predat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_dat['hm20'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore / visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figpath = load_utils.get_onedrive_path('emaval_fig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_dat['hm18'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub, dat in ema_dat.items():\n",
    "\n",
    "    daystart = dat['dates'].iloc[0]\n",
    "\n",
    "    dayend = dat['dates'].iloc[-1]\n",
    "\n",
    "    daystart = sel_info.loc[sub]['onboarding_date'] + dt.timedelta(days=1)\n",
    "    dayend = sel_info.loc[sub]['checkout_date'] - dt.timedelta(days=1)\n",
    "\n",
    "\n",
    "    ndays = (dayend - daystart).days\n",
    "\n",
    "    \n",
    "    compl_perc = dat.shape[0] / (ndays * 6)\n",
    "\n",
    "    print(f'{sub}: over {ndays} days completed {np.round(compl_perc, 2)}')\n",
    "\n",
    "\n",
    "# ema_dat['hm18']['dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.stats as utilsstat\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
