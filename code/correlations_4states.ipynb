{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-clinic data to validate EMA with UPDRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import packages\n",
    "\n",
    "- document versions for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import importlib\n",
    "from itertools import product, compress\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.signal import welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 2.3.2\n",
      "numpy 2.3.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nPython sys 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\\npandas 2.1.1\\nnumpy 1.26.0\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "# print('sci-py', scipy.__version__)\n",
    "# print('sci-kit learn', sk.__version__)\n",
    "# print('matplotlib', plt_version)\n",
    "\n",
    "\"\"\"\n",
    "Python sys 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
    "pandas 2.1.1\n",
    "numpy 1.26.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyPerceive folder added: c:\\Users\\habetsj\\Research\\projects\\PyPerceive\\code\n"
     ]
    }
   ],
   "source": [
    "from utils import load_utils, load_data, prep_data\n",
    "# from PerceiveImport.classes import main_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.load_utils' from 'c:\\\\Users\\\\habetsj\\\\Research\\\\projects\\\\EMA_validation\\\\EMA_clinic_validation\\\\code\\\\utils\\\\load_utils.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOR DEBUGGING\n",
    "importlib.reload(load_data)\n",
    "importlib.reload(load_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "figpath = load_utils.get_onedrive_path('emaval_fig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import EMA and UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SINGLE CONDITION\n",
    "# CONDITION = 'm0s0'\n",
    "\n",
    "# ema_df, updrs_df = load_data.get_EMA_UPDRS_data(condition=CONDITION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_data)\n",
    "importlib.reload(load_utils)\n",
    "\n",
    "\n",
    "# list of IDs to exclude bcs data is still missing\n",
    "excl_ids = []  # 'ema31', 'ema32', 'ema33', 'ema34'\n",
    "\n",
    "# 4 CONDITIONS\n",
    "EMA, UPDRS = {}, {}\n",
    "\n",
    "for COND in ['m0s0', 'm0s1', 'm1s0', 'm1s1']:\n",
    "    ema_temp, updrs_temp = load_data.get_EMA_UPDRS_data(\n",
    "        condition=COND, CONVERT_SCORES=True,\n",
    "    )\n",
    "    EMA[COND] = ema_temp\n",
    "    UPDRS[COND] = updrs_temp\n",
    "\n",
    "    # print(f'EMA ids: {EMA[COND][\"study_id\"]}')\n",
    "    # print(f'UPDRS ids: {UPDRS[COND][\"study_id\"]}')\n",
    "\n",
    "    for ema_n_excl in excl_ids:\n",
    "        if ema_n_excl in EMA[COND]['study_id'].values:\n",
    "            drop_idx = np.where(EMA[COND]['study_id'] == ema_n_excl)[0][0]\n",
    "            EMA[COND] = EMA[COND].drop(drop_idx).reset_index(drop=True)\n",
    "            print(f'drop {ema_n_excl} in EMA, index: {drop_idx}')\n",
    "        if ema_n_excl in UPDRS[COND]['study_id'].values:\n",
    "            drop_idx = np.where(UPDRS[COND]['study_id'] == ema_n_excl)[0][0]\n",
    "            UPDRS[COND] = UPDRS[COND].drop(drop_idx).reset_index(drop=True)\n",
    "            print(f'drop {ema_n_excl} in UPDRS, index: {drop_idx}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get (mean-corrected) EMA and UPDRS values per symptom subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_data)\n",
    "\n",
    "importlib.reload(prep_data)\n",
    "\n",
    "\n",
    "sumdf = prep_data.get_sum_df(EMA_dict=EMA, UPDRS_dict=UPDRS,\n",
    "                             MEAN_CORR=True,)\n",
    "\n",
    "# sumdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in Training and Test Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA IN TRAIN AND TEST\n",
    "\n",
    "train_subs, test_subs = prep_data.get_train_test_split(sumdf)\n",
    "\n",
    "traindf = sumdf.loc[[i for i in sumdf.index if i in train_subs]]\n",
    "\n",
    "testdf = sumdf.loc[[i for i in sumdf.index if i in test_subs]]\n",
    "\n",
    "print(traindf.shape, testdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical comparison of training and test cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable 1, EMA_SUM_brady_m0s0: stat: 78.0, p=0.4454\n",
      "Variable 2, EMA_SUM_tremor_m0s0: stat: 97.0, p=0.9825\n",
      "Variable 3, EMA_SUM_gait_m0s0: stat: 92.5, p=0.8958\n",
      "Variable 4, EMA_SUM_nonmotor_m0s0: stat: 81.5, p=0.5407\n",
      "Variable 5, UPDRS_SUM_brady_m0s0: stat: 80.5, p=0.5129\n",
      "Variable 6, UPDRS_SUM_tremor_m0s0: stat: 80.0, p=0.4962\n",
      "Variable 7, UPDRS_SUM_gait_m0s0: stat: 84.5, p=0.6263\n",
      "Variable 8, EMA_SUM_brady_m0s1: stat: 123.0, p=0.1674\n",
      "Variable 9, EMA_SUM_tremor_m0s1: stat: 85.5, p=0.7852\n",
      "Variable 10, EMA_SUM_gait_m0s1: stat: 125.0, p=0.1403\n",
      "Variable 11, EMA_SUM_nonmotor_m0s1: stat: 117.0, p=0.2669\n",
      "Variable 12, UPDRS_SUM_brady_m0s1: stat: 111.5, p=0.3908\n",
      "Variable 13, UPDRS_SUM_tremor_m0s1: stat: 118.5, p=0.2375\n",
      "Variable 14, UPDRS_SUM_gait_m0s1: stat: 92.0, p=1.0\n",
      "Variable 15, EMA_SUM_brady_m1s0: stat: 43.0, p=0.3238\n",
      "Variable 16, EMA_SUM_tremor_m1s0: stat: 36.5, p=0.7287\n",
      "Variable 17, EMA_SUM_gait_m1s0: stat: 34.5, p=0.882\n",
      "Variable 18, EMA_SUM_nonmotor_m1s0: stat: 47.0, p=0.1671\n",
      "Variable 19, UPDRS_SUM_brady_m1s0: stat: 27.0, p=0.9575\n",
      "Variable 20, UPDRS_SUM_tremor_m1s0: stat: 20.0, p=0.4233\n",
      "Variable 21, UPDRS_SUM_gait_m1s0: stat: 33.5, p=0.5945\n",
      "Variable 22, EMA_SUM_brady_m1s1: stat: 17.5, p=0.2053\n",
      "Variable 23, EMA_SUM_tremor_m1s1: stat: 28.5, p=0.9156\n",
      "Variable 24, EMA_SUM_gait_m1s1: stat: 18.5, p=0.2457\n",
      "Variable 25, EMA_SUM_nonmotor_m1s1: stat: 17.0, p=0.1874\n",
      "Variable 26, UPDRS_SUM_brady_m1s1: stat: 40.0, p=0.3413\n",
      "Variable 27, UPDRS_SUM_tremor_m1s1: stat: 36.0, p=0.5815\n",
      "Variable 28, UPDRS_SUM_gait_m1s1: stat: 26.0, p=0.7245\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, len(traindf.keys()), \n",
    "                         sharey='row', figsize=(12, 3))\n",
    "\n",
    "yticks = [-10, -5, 0, 5, 10]\n",
    "\n",
    "for i_ft, ft in enumerate(list(testdf.keys())):\n",
    "\n",
    "    train = traindf[ft].values\n",
    "    train = train[~np.isnan(train)]\n",
    "    test = testdf[ft].values\n",
    "    test = test[~np.isnan(test)]\n",
    "\n",
    "    axes[i_ft].boxplot([train, test])\n",
    "    axes[i_ft].set_xlabel(f'#{i_ft+1}')\n",
    "\n",
    "    # do stats\n",
    "    stat, p = mannwhitneyu(train, test)\n",
    "    print(f'Variable {i_ft+1}, {ft}: stat: {stat}, p={round(p, 4)}')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines[['right', 'top', 'left', 'bottom']].set_visible(False)\n",
    "    for y in yticks: ax.axhline(y, alpha=.3, color='gray',)\n",
    "\n",
    "axes[0].set_yticks(yticks)\n",
    "axes[0].set_yticklabels(yticks)\n",
    "axes[0].set_ylabel('variable change (points)')\n",
    "\n",
    "plt.suptitle('Intra-individual changes in EMA / UPDRS per therapy condition: training vs test cohort')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figpath, 'train_data', 'training_vs_test_vars'), dpi=300,\n",
    "            facecolor='w',)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore EMA x UPDRS correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_EMA_UPDRS(\n",
    "    ax, dat_df,\n",
    "    EMA_subscore = 'brady',\n",
    "    UPDRS_subscore = 'brady',\n",
    "    show_updrs_improve=True,\n",
    "):\n",
    "\n",
    "    ema_values, updrs_values = [], []\n",
    "\n",
    "    for COND in ['m0s0', 'm0s1', 'm1s0', 'm1s1']:\n",
    "\n",
    "        ema_v = dat_df[f'EMA_SUM_{EMA_subscore}_{COND}']\n",
    "        updrs_v = dat_df[f'UPDRS_SUM_{UPDRS_subscore}_{COND}']\n",
    "\n",
    "        nan_sel = np.logical_or(pd.isna(ema_v), pd.isna(updrs_v))\n",
    "        ema_v = ema_v[~nan_sel]\n",
    "        updrs_v = updrs_v[~nan_sel]\n",
    "\n",
    "        ema_values.extend(ema_v)\n",
    "        updrs_values.extend(updrs_v)\n",
    "\n",
    "    # plot UPDRS clinical IMPROVEMENT\n",
    "    if show_updrs_improve:\n",
    "        updrs_values = np.array(updrs_values) * -1\n",
    "        ax.set_xlabel(f'UPDRS-improvement {UPDRS_subscore}\\n(high: less symptoms)')\n",
    "    \n",
    "    else:\n",
    "        ax.set_xlabel(f'UPDRS {UPDRS_subscore}\\n(low: less symptoms)')\n",
    "\n",
    "\n",
    "    ax.scatter(updrs_values, ema_values)\n",
    "    ax.axhline(y=0, c='gray', alpha=0.3)\n",
    "    ax.axvline(x=0, c='gray', alpha=0.3)\n",
    "\n",
    "    R, pval = pearsonr(\n",
    "        [x for x in updrs_values if not np.isnan(x)],\n",
    "        [y for y in ema_values if not np.isnan(y)]\n",
    "    )\n",
    "\n",
    "    ax.set_title(f'{EMA_subscore}  R: {R.round(2)}, p={pval.round(5)}')\n",
    "    ax.set_ylabel(f'EMA {EMA_subscore}\\n(high: less symptoms)')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figname = 'motor_corr_meanCorrvalues_2411'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "for ax, subscore in zip(axes, ['brady', 'tremor', 'gait']):\n",
    "\n",
    "    ax = scatter_EMA_UPDRS(\n",
    "        ax=ax, dat_df=traindf,\n",
    "        EMA_subscore=subscore,\n",
    "        UPDRS_subscore=subscore,\n",
    "        show_updrs_improve=True,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(figpath, 'train_data', 'ema_updrs_corr', figname), dpi=300,\n",
    "            facecolor='w',)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats ema x updrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traindf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(prep_data)\n",
    "\n",
    "\n",
    "lmm_df = prep_data.get_lmm_df(traindf)\n",
    "\n",
    "print(lmm_df.values.shape)\n",
    "\n",
    "print(lmm_df.columns)\n",
    "\n",
    "print(lmm_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.stats as utilsstat\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utilsstat)\n",
    "\n",
    "# set target motor symptom\n",
    "motor_target = 'brady'\n",
    "\n",
    "lmm_fix = {\n",
    "    'single_motor': f\"EMA_SUM_{motor_target} + EMA_SUM_nonmotor\",\n",
    "    'all_motor': (\n",
    "        \"EMA_SUM_brady + EMA_SUM_tremor + \"\n",
    "        \"EMA_SUM_gait + EMA_SUM_nonmotor\"\n",
    "    )\n",
    "}\n",
    "\n",
    "FIX_EFF = 'all_motor'\n",
    "\n",
    "# Random intercepts only\n",
    "model = smf.mixedlm(\n",
    "    f\"UPDRS_SUM_{motor_target} ~ {lmm_fix[FIX_EFF]}\",\n",
    "    lmm_df,\n",
    "    groups=lmm_df[\"subid\"],\n",
    "    # re_formula=f\"~EMA_SUM_{motor_target}\",  # for random slopes for EMA motor\n",
    ")\n",
    "result = model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "## calculate explained variances\n",
    "R2_marg, R2_cond = utilsstat.calc_expl_variances(fitted_model=result)\n",
    "\n",
    "print(f\"for {motor_target}: R2_marginal {np.round(R2_marg, 3)},\"\n",
    "      f\"R2_conditional: {np.round(R2_cond, 3)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show individual differences in EMA-point vs UPDRS-change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4),\n",
    "                         sharey=True, )\n",
    "\n",
    "for i_trg, target in enumerate(['brady', 'tremor', 'gait']):\n",
    "\n",
    "    id_coefs = []\n",
    "\n",
    "    for subid in np.unique(lmm_df['subid']):\n",
    "\n",
    "        x = lmm_df[f'EMA_SUM_{target}'][lmm_df['subid'] == subid]\n",
    "        y = lmm_df[f'UPDRS_SUM_{target}'][lmm_df['subid'] == subid]\n",
    "\n",
    "        try:\n",
    "            z = np.polyfit(x, y, 1)\n",
    "            coef = z[0]\n",
    "        except:\n",
    "            if all(x == y): coef = 0\n",
    "\n",
    "        id_coefs.append(coef)\n",
    "        # plt.scatter(x, y)\n",
    "        xplot = np.arange(5)\n",
    "        # plt.plot(xplot, xplot * coef)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    axes[i_trg].hist(id_coefs)\n",
    "    axes[i_trg].set_xlabel('delta UPDRS point / EMA point')\n",
    "    axes[i_trg].set_ylabel(f'Observations for {target} (n subjects)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-out Validation: UPDRS prediction based on EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import r2_score, confusion_matrix\n",
    "from scipy.stats import f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holdout_results(traindf, testdf,\n",
    "                        target, FEAT_SEL,\n",
    "                        classif='linreg',\n",
    "                        verbose=False,\n",
    "                        SHUFFLE=False,\n",
    "                        PERM_SEED=False):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "        - y_true\n",
    "        - y_pred\n",
    "        - R2\n",
    "        - F-test\n",
    "    \"\"\"\n",
    "    # print(f'\\n{target} prediction, {FEAT_SEL}-variable')\n",
    "    X_col_sel = {\n",
    "        'single': [f'EMA_SUM_{target}'],\n",
    "        'multi': ['EMA_SUM_brady', 'EMA_SUM_tremor',\n",
    "                  'EMA_SUM_gait', 'EMA_SUM_nonmotor']\n",
    "    }\n",
    "\n",
    "\n",
    "    # train cohort\n",
    "    train_pred_df = prep_data.get_lmm_df(traindf)  # create sample wise df\n",
    "    X_train = train_pred_df[X_col_sel[FEAT_SEL]].values\n",
    "    if target == 'updrs_sum':\n",
    "        # predict motor UPDRS change\n",
    "        y_train = np.sum(train_pred_df[['UPDRS_SUM_brady', 'UPDRS_SUM_tremor',\n",
    "                                'UPDRS_SUM_gait']], axis=1).values\n",
    "    else:\n",
    "        y_train = train_pred_df[f'UPDRS_SUM_{target}'].values\n",
    "    \n",
    "    if SHUFFLE:\n",
    "        np.random.seed(PERM_SEED)\n",
    "        np.random.shuffle(y_train)\n",
    "\n",
    "    # test cohort\n",
    "    test_pred_df = prep_data.get_lmm_df(testdf)  # create sample wise df\n",
    "    X_test = test_pred_df[X_col_sel[FEAT_SEL]].values\n",
    "    if target == 'updrs_sum':\n",
    "        y_true = np.sum(test_pred_df[['UPDRS_SUM_brady', 'UPDRS_SUM_tremor',\n",
    "                                  'UPDRS_SUM_gait']], axis=1)\n",
    "    else:\n",
    "        y_true = test_pred_df[f'UPDRS_SUM_{target}'].values\n",
    "    \n",
    "    # Run prediction\n",
    "    models = {'linreg': LinearRegression(),\n",
    "              'lda': LDA(),\n",
    "              'logreg': LogisticRegression()}\n",
    "    model = models[classif]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evauate predictions\n",
    "\n",
    "    # F-statistic for model usability\n",
    "    \n",
    "    # Sum of squares\n",
    "    SSR = np.sum((y_pred - np.mean(y_true)) ** 2)   # Regression\n",
    "    SSE = np.sum((y_true - y_pred) ** 2)   # Error\n",
    "    SST = np.sum((y_true - np.mean(y_true)) ** 2)   # Total\n",
    "\n",
    "    # Degrees of freedom\n",
    "    df_reg = X_test.shape[1]\n",
    "    df_err = len(y_true) - (X_test.shape[1] + 1)  # +1 for coeff next to betas of features\n",
    "\n",
    "    # Mean squares\n",
    "    MSR = SSR / df_reg if df_reg > 0 else np.nan\n",
    "    MSE = SSE / df_err if df_err > 0 else np.nan\n",
    "    F = MSR / MSE\n",
    "    # p-value for the observed F\n",
    "    f_pval = 1 - f.cdf(F, df_reg, df_err)\n",
    "    # critical F threshold at alpha\n",
    "    f_crit = f.ppf(1 - .05, df_reg, df_err)\n",
    "    # print(f'F-test is {F}, p: {f_pval}')\n",
    "\n",
    "    # R-squared\n",
    "    R2 = r2_score(y_true=y_true, y_pred=y_pred,)\n",
    "    R2b = SSR / SST\n",
    "    # print(f'R-squared is {R2}')\n",
    "\n",
    "    if verbose:\n",
    "        print(f'{target}, {FEAT_SEL}: R2 {np.round(R2, 2)}, F-stat '\n",
    "              f'{np.round(F, 1)}, p = {np.round(f_pval, 4)}')\n",
    "\n",
    "    return y_true, y_pred, R2, F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for TARGET, FT_SEL in product(\n",
    "    ['brady', 'tremor', 'gait'],\n",
    "    ['single', 'multi']\n",
    "):\n",
    "\n",
    "    (y_true, y_pred, R2, f_test) = get_holdout_results( \n",
    "        traindf=traindf,\n",
    "        target=TARGET,\n",
    "        testdf=testdf,\n",
    "        FEAT_SEL=FT_SEL,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'updrs_sum'\n",
    "FT_SEL = 'multi'\n",
    "\n",
    "(y_true, y_pred, R2, f_test) = get_holdout_results( \n",
    "    traindf=traindf,\n",
    "    target=target,\n",
    "    testdf=testdf,\n",
    "    FEAT_SEL=FT_SEL,\n",
    ")\n",
    "\n",
    "true_stats = {'r2': R2, 'f': f_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n"
     ]
    }
   ],
   "source": [
    "N_PERM = 500\n",
    "target = 'updrs_sum'\n",
    "FT_SEL = 'multi'\n",
    "\n",
    "perm_stats = {'r2': [], 'f': []}\n",
    "\n",
    "\n",
    "for i_perm in np.arange(N_PERM):\n",
    "    # print(i_perm)\n",
    "    (_, _, r2temp, ftemp) = get_holdout_results( \n",
    "        traindf=traindf,\n",
    "        target=target,\n",
    "        testdf=testdf,\n",
    "        FEAT_SEL=FT_SEL,\n",
    "        SHUFFLE=True,\n",
    "        PERM_SEED=i_perm,\n",
    "    )\n",
    "    perm_stats['r2'].append(r2temp)\n",
    "    perm_stats['f'].append(ftemp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "\n",
    "ax.scatter(y_true, y_pred)\n",
    "\n",
    "ax.set_xlabel('true change (points)', size=14,)\n",
    "ax.set_ylabel('predicted change (points)', size=14,)\n",
    "ax.set_title('Intra-individual UPDRS-fluctuations\\n(brady+tremor+gait)',\n",
    "             size=14,)\n",
    "\n",
    "ax.tick_params(axis='both', size=14, labelsize=14,)\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "# ax.legend(frameon=False, fontsize=14,\n",
    "#                bbox_to_anchor=(.95, .5), loc='center left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(load_utils.get_onedrive_path('figures'),\n",
    "             'ema_updrs_corr', 'holdoutval_updrsSum'),\n",
    "             dpi=300, facecolor='w',)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric r2: p = 0.0\n",
      "metric f: p = 0.0\n"
     ]
    }
   ],
   "source": [
    "### plot significnaces from permutations\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "\n",
    "for i_ax, metr in enumerate(list(perm_stats.keys())):\n",
    "\n",
    "    axes[i_ax].hist(perm_stats[metr], color='gray', alpha=.5,)\n",
    "    axes[i_ax].axvline(np.percentile(perm_stats[metr], 95),\n",
    "                       color='orange', alpha=.8, lw=3,\n",
    "                       label='permuted\\nalpha 0.05',)\n",
    "    \n",
    "    axes[i_ax].axvline(true_stats[metr],\n",
    "                       color='purple', alpha=.5, lw=1,\n",
    "                       label='prediction',)\n",
    "    \n",
    "    p_calc = sum(np.array(perm_stats[metr]) > true_stats[metr]) / len(perm_stats[metr])\n",
    "    print(f'metric {metr}: p = {np.round(p_calc, 3)}')\n",
    "\n",
    "    axes[i_ax].set_xlabel(f'{metr} score', size=14,)\n",
    "\n",
    "    axes[i_ax].set_ylabel('count (n)', size=14)\n",
    "\n",
    "    axes[i_ax].tick_params(axis='both', size=14, labelsize=14,)\n",
    "    axes[i_ax].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "axes[1].legend(frameon=False, fontsize=14,\n",
    "               bbox_to_anchor=(.95, .5), loc='center left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(load_utils.get_onedrive_path('figures'),\n",
    "             'ema_updrs_corr', f'holdOut_updrsSum_{N_PERM}permStats'),\n",
    "             dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT AS HEATMAP\n",
    "HOP = 4\n",
    "\n",
    "allvalues = [int(v) for v in y_true.values] + [int(v) for v in y_pred]\n",
    "# Ensure labels are sorted and complete\n",
    "labels = np.arange(np.min(allvalues) // HOP, np.max(allvalues) // HOP)\n",
    "\n",
    "# Compute confusion matrix\n",
    "plot_true = y_true // HOP\n",
    "plot_pred = y_pred // HOP\n",
    "cm = confusion_matrix(plot_true, plot_pred, labels=labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "im = ax.imshow(cm, cmap=\"viridis\", vmax=1,)\n",
    "\n",
    "# # Add numbers inside cells\n",
    "# for i in range(cm.shape[0]):\n",
    "#     for j in range(cm.shape[1]):\n",
    "#         ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "# Axes labels\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_yticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels([l * HOP for l in labels])\n",
    "ax.set_yticklabels([l * HOP for l in labels])\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.set_label(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFP analysis (not included)\n",
    "\n",
    "to do's:\n",
    "- double check \"rest\" task is not excluding data\n",
    "- include stim-amplitude data rows to double s0 vs s1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ids = load_data.get_ids()\n",
    "\n",
    "SKIP_LFPs = {\n",
    "    'ema03': ['m0s1'],\n",
    "    'ema07': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema09': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema10': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema12': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema14': 'all',  # no m1 done, m0s1 not found in motherfolder\n",
    "    # 'ema14': ['m1s0', 'm1s1', 'm0s1'],  # ONLY m0s0; EXCLUDE?!\n",
    "    'ema15': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema16': ['m1s0', 'm1s1']  # ONLY m0s0; EXCLUDE?!\n",
    "    # 'ema16': 'all'  # no m1 done: always ['m1s0', 'm1s1']\n",
    "}\n",
    "\n",
    "lfp_data = {}\n",
    "\n",
    "for ema_id, COND in product(ids.index,\n",
    "                            ['m0s0', 'm0s1', 'm1s0', 'm1s1']):\n",
    "    if ema_id in SKIP_LFPs.keys():\n",
    "        if COND in SKIP_LFPs[ema_id] or SKIP_LFPs[ema_id] == 'all':\n",
    "            print(f'\\n#### SKIP {ema_id} {COND}, not percept ready ####\\n')\n",
    "            continue\n",
    "\n",
    "    sub = ids.loc[ema_id]['prc_id']\n",
    "    ses = ids.loc[ema_id]['prc_ses']\n",
    "\n",
    "    print(f'\\nGET LFP {ema_id}, {sub}, {ses}, {COND}')\n",
    "\n",
    "    # load session that corresponds to current selection\n",
    "    ### TODO: 'REST' is hardcoded currently, check for issues with task like rest&tap\n",
    "    sub_data = main_class.PerceiveData(\n",
    "        sub = sub, \n",
    "        incl_modalities=['streaming'],\n",
    "        incl_session = [ses],\n",
    "        incl_condition =[COND,],\n",
    "        incl_task = [\"rest\"],\n",
    "        import_json=False, # for addtionally loading the corresponding JSON files as source files, set to True\n",
    "        warn_for_metaNaNs=True, # True will give you a warning with rows from the metadata table with NaNs. Make sure you have filled out all columns of the file you want to load.\n",
    "        allow_NaNs_in_metadata=True,\n",
    "    )\n",
    "\n",
    "    dat = getattr(sub_data.streaming, ses)\n",
    "    # only include first two data rows (left and right STN signal)\n",
    "    dat = getattr(dat, COND).rest.run1.data.get_data()[:2, :]\n",
    "    ### TODO: include stimulation amplitude data streams to double check whether s0 vs s1 is correct\n",
    "    lfp_data[f'{ema_id}_{COND}'] = dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG_PATH = os.path.join(os.path.dirname(os.getcwd()), 'figures', 'lfp_preprocess')\n",
    "FIG_PATH = load_utils.get_onedrive_path('emaval_fig')\n",
    "print(f'CHECK FIG_PATH: {FIG_PATH}, exists? -> {os.path.exists(FIG_PATH)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_lfp_preprocess(\n",
    "    DAT,\n",
    "    SUB = 'emaXX',\n",
    "    COND = 'm0s0',\n",
    "    N_STD_OUTLIER = 3,\n",
    "    LOWPASS = 2,\n",
    "    HIGHPASS = 45,\n",
    "    SFREQ=250,\n",
    "    SHOWPLOTS=False,\n",
    "    SAVEPLOTS=True,\n",
    "):\n",
    "    lfp_times = prep_data.get_lfp_times()\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2)\n",
    "    for i, (arr, side) in enumerate(\n",
    "        zip(DAT[f'{SUB}_{COND}'][:2], ['left', 'right'])\n",
    "    ):\n",
    "        arr = arr.copy()  # do not overwrite original dict data\n",
    "\n",
    "        if ids.loc[SUB]['prc_id'] in lfp_times.keys():\n",
    "            t_start, t_end = lfp_times[ids.loc[SUB]['prc_id']][COND]['rest']\n",
    "            i_start, i_end = (t_start * 250, t_end * 250)\n",
    "            arr = arr[i_start:i_end]\n",
    "\n",
    "        ### plot raw signal\n",
    "        axes[0, i].plot(arr, color='blue', alpha=.3, label='raw filtered',)\n",
    "\n",
    "        ### handle outliers\n",
    "        sel = np.logical_or(arr > (N_STD_OUTLIER * np.std(arr)),\n",
    "                            arr < (-N_STD_OUTLIER * np.std(arr)))\n",
    "        # arr[sel] = np.nan  # replace outliers with NaNs\n",
    "        arr = arr[~sel]  # drop outliers\n",
    "        \n",
    "        ### plot resulting arr\n",
    "        axes[0, i].plot(arr, color='blue', label='cleaned',)\n",
    "        axes[0, i].set_title(f'{SUB} {COND} {side} STN', weight='bold')\n",
    "        axes[0, i].set_ylabel(f'{side}-STN activity (yVolt)')\n",
    "        xticks = np.arange(0, len(arr), 250 * 60)\n",
    "        axes[0, i].set_xticks(xticks)\n",
    "        axes[0, i].set_xticklabels(np.arange(len(xticks)))\n",
    "        axes[0, i].set_xlabel('Time (minutes)')\n",
    "        axes[0, i].set_ylim(-50, 50)\n",
    "        # axes[0, i].legend(loc='upper right', frameon=False,)  # legend\n",
    "\n",
    "        ### plot PSD\n",
    "        arr = prep_data.lfp_filter(signal=arr, low=LOWPASS, high=HIGHPASS,)\n",
    "        f, psx = welch(arr, fs=SFREQ,)\n",
    "        axes[1, i].plot(f, psx)\n",
    "        axes[1, i].set_ylabel(f'{side}-STN Power (a.u.)')\n",
    "        axes[1, i].set_xlim(0, 45)\n",
    "        axes[1, i].set_xlabel('Freq (Hz)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVEPLOTS:\n",
    "        plt.savefig(os.path.join(FIG_PATH, 'lfp_preprocess', f'PSD_check_{SUB}_{COND}'),\n",
    "                    facecolor='w', dpi=150,)\n",
    "    if SHOWPLOTS: plt.show()\n",
    "    else: plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK missing LFP sessions\n",
    "\n",
    "check motherfolder:\n",
    "- ema16, sub105: too many runs? UPDRS tasks? 3 rest m0s0, 2 rest m0s1?\n",
    "- ema14: only m0s0, leave out only one state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_done = np.unique([k.split('_')[0] for k in lfp_data.keys()])\n",
    "\n",
    "lfp_todo = [s for s in ids.index if s not in lfp_done]\n",
    "\n",
    "print(lfp_todo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in lfp_todo:\n",
    "\n",
    "    print(f'\\n{sub}  -> sub-{ids.loc[sub][\"prc_id\"]} @ {ids.loc[sub][\"prc_ses\"]}')\n",
    "    for COND in ['m0s0', 'm0s1', 'm1s0', 'm1s1']:\n",
    "        print(f'\\t{COND}')\n",
    "        sub_data = main_class.PerceiveData(\n",
    "            sub = ids.loc[sub]['prc_id'],\n",
    "            incl_modalities=['streaming'],\n",
    "            incl_session = [ids.loc[sub]['prc_ses']],\n",
    "            incl_condition =[COND,],\n",
    "            incl_task = [\"rest\"],\n",
    "            import_json=False, # for addtionally loading the corresponding JSON files as source files, set to True\n",
    "            warn_for_metaNaNs=True, # True will give you a warning with rows from the metadata table with NaNs. Make sure you have filled out all columns of the file you want to load.\n",
    "            allow_NaNs_in_metadata=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select relevant ephys epochs based on task timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_times = prep_data.get_lfp_times()\n",
    "ids = load_data.get_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 250\n",
    "sub = 'ema01'\n",
    "con = 'm0s0'\n",
    "lfp_sub = ids.loc[sub]['prc_id']\n",
    "\n",
    "rest_times = lfp_times[lfp_sub][con]['rest']\n",
    "rest_samples = [rest_times[0] * Fs, rest_times[1] * Fs]\n",
    "\n",
    "plt.plot(lfp_data[f'{sub}_{con}'][0][rest_samples[0]:rest_samples[1]])\n",
    "\n",
    "### TODO:\n",
    "# check if all seconds for available data is working\n",
    "# correct 'rest' tasks if troublesome i.e. rest&tap\n",
    "# check s0 and s1 versus stim-ampltidude time series\n",
    "# plot individual PSDs\n",
    "# calculate beta-powers X UPDRS correlations\n",
    "# draft if and if so, how to include movement parts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and save spectral preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_subs = np.unique([k.split('_')[0] for k in lfp_data.keys()])\n",
    "\n",
    "# lfp_subs = ['ema01', 'ema08']\n",
    "\n",
    "for SUB, COND in product(lfp_subs, ['m0s0', 'm0s1', 'm1s0', 'm1s1']):\n",
    "\n",
    "    print(f'\\n### {SUB}, {COND}')\n",
    "    if f'{SUB}_{COND}' not in lfp_data.keys():\n",
    "        print(f'...skip {SUB}, {COND}')\n",
    "        continue\n",
    "\n",
    "    plot_single_lfp_preprocess(SUB=SUB, COND=COND, DAT=lfp_data,\n",
    "                               N_STD_OUTLIER=6,\n",
    "                               SHOWPLOTS=False, SAVEPLOTS=True,)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
