{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-clinic data to validate EMA with UPDRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import packages\n",
    "\n",
    "- document versions for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import importlib\n",
    "from itertools import product, compress\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.signal import welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "# print('sci-py', scipy.__version__)\n",
    "# print('sci-kit learn', sk.__version__)\n",
    "# print('matplotlib', plt_version)\n",
    "\n",
    "\"\"\"\n",
    "Python sys 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
    "pandas 2.1.1\n",
    "numpy 1.26.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_utils, load_data, prep_data\n",
    "# from PerceiveImport.classes import main_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEBUGGING\n",
    "importlib.reload(load_data)\n",
    "importlib.reload(load_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import EMA and UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SINGLE CONDITION\n",
    "# CONDITION = 'm0s0'\n",
    "\n",
    "# ema_df, updrs_df = load_data.get_EMA_UPDRS_data(condition=CONDITION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_data)\n",
    "importlib.reload(load_utils)\n",
    "\n",
    "\n",
    "# list of IDs to exclude bcs data is still missing\n",
    "excl_ids = []  # 'ema31', 'ema32', 'ema33', 'ema34'\n",
    "\n",
    "# 4 CONDITIONS\n",
    "EMA, UPDRS = {}, {}\n",
    "\n",
    "for COND in ['m0s0', 'm0s1', 'm1s0', 'm1s1']:\n",
    "    ema_temp, updrs_temp = load_data.get_EMA_UPDRS_data(\n",
    "        condition=COND, CONVERT_SCORES=True,\n",
    "    )\n",
    "    EMA[COND] = ema_temp\n",
    "    UPDRS[COND] = updrs_temp\n",
    "\n",
    "    # print(f'EMA ids: {EMA[COND][\"study_id\"]}')\n",
    "    # print(f'UPDRS ids: {UPDRS[COND][\"study_id\"]}')\n",
    "\n",
    "    for ema_n_excl in excl_ids:\n",
    "        if ema_n_excl in EMA[COND]['study_id'].values:\n",
    "            drop_idx = np.where(EMA[COND]['study_id'] == ema_n_excl)[0][0]\n",
    "            EMA[COND] = EMA[COND].drop(drop_idx).reset_index(drop=True)\n",
    "            print(f'drop {ema_n_excl} in EMA, index: {drop_idx}')\n",
    "        if ema_n_excl in UPDRS[COND]['study_id'].values:\n",
    "            drop_idx = np.where(UPDRS[COND]['study_id'] == ema_n_excl)[0][0]\n",
    "            UPDRS[COND] = UPDRS[COND].drop(drop_idx).reset_index(drop=True)\n",
    "            print(f'drop {ema_n_excl} in UPDRS, index: {drop_idx}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get (mean-corrected) EMA and UPDRS values per symptom subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_data)\n",
    "\n",
    "importlib.reload(prep_data)\n",
    "\n",
    "\n",
    "sumdf = prep_data.get_sum_df(EMA_dict=EMA, UPDRS_dict=UPDRS,\n",
    "                             MEAN_CORR=True,)\n",
    "\n",
    "# sumdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in Training and Test Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA IN TRAIN AND TEST\n",
    "\n",
    "train_subs, test_subs = prep_data.get_train_test_split(sumdf)\n",
    "\n",
    "traindf = sumdf.loc[[i for i in sumdf.index if i in train_subs]]\n",
    "\n",
    "testdf = sumdf.loc[[i for i in sumdf.index if i in test_subs]]\n",
    "\n",
    "print(traindf.shape, testdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore EMA x UPDRS correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_EMA_UPDRS(\n",
    "    ax, dat_df,\n",
    "    EMA_subscore = 'brady',\n",
    "    UPDRS_subscore = 'brady',\n",
    "    show_updrs_improve=True,\n",
    "):\n",
    "\n",
    "    ema_values, updrs_values = [], []\n",
    "\n",
    "    for COND in ['m0s0', 'm0s1', 'm1s0', 'm1s1']:\n",
    "\n",
    "        ema_v = dat_df[f'EMA_SUM_{EMA_subscore}_{COND}']\n",
    "        updrs_v = dat_df[f'UPDRS_SUM_{UPDRS_subscore}_{COND}']\n",
    "\n",
    "        nan_sel = np.logical_or(pd.isna(ema_v), pd.isna(updrs_v))\n",
    "        ema_v = ema_v[~nan_sel]\n",
    "        updrs_v = updrs_v[~nan_sel]\n",
    "\n",
    "        ema_values.extend(ema_v)\n",
    "        updrs_values.extend(updrs_v)\n",
    "\n",
    "    # plot UPDRS clinical IMPROVEMENT\n",
    "    if show_updrs_improve:\n",
    "        updrs_values = np.array(updrs_values) * -1\n",
    "        ax.set_xlabel(f'UPDRS-improvement {UPDRS_subscore}\\n(high: less symptoms)')\n",
    "    \n",
    "    else:\n",
    "        ax.set_xlabel(f'UPDRS {UPDRS_subscore}\\n(low: less symptoms)')\n",
    "\n",
    "\n",
    "    ax.scatter(updrs_values, ema_values)\n",
    "    ax.axhline(y=0, c='gray', alpha=0.3)\n",
    "    ax.axvline(x=0, c='gray', alpha=0.3)\n",
    "\n",
    "    R, pval = pearsonr(\n",
    "        [x for x in updrs_values if not np.isnan(x)],\n",
    "        [y for y in ema_values if not np.isnan(y)]\n",
    "    )\n",
    "\n",
    "    ax.set_title(f'{EMA_subscore}  R: {R.round(2)}, p={pval.round(5)}')\n",
    "    ax.set_ylabel(f'EMA {EMA_subscore}\\n(high: less symptoms)')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figpath = load_utils.get_onedrive_path('emaval_fig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figname = 'motor_corr_meanCorrvalues_brady9'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "for ax, subscore in zip(axes, ['brady', 'tremor', 'gait']):\n",
    "\n",
    "    ax = scatter_EMA_UPDRS(\n",
    "        ax=ax, dat_df=traindf,\n",
    "        EMA_subscore=subscore,\n",
    "        UPDRS_subscore=subscore,\n",
    "        show_updrs_improve=True,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(figpath, 'train_data', 'ema_updrs_corr', figname), dpi=300,\n",
    "            facecolor='w',)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats ema x updrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traindf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(prep_data)\n",
    "\n",
    "\n",
    "lmm_df = prep_data.get_lmm_df(traindf)\n",
    "\n",
    "print(lmm_df.values.shape)\n",
    "\n",
    "print(lmm_df.columns)\n",
    "\n",
    "print(lmm_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.stats as utilsstat\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utilsstat)\n",
    "\n",
    "# set target motor symptom\n",
    "motor_target = 'brady'\n",
    "\n",
    "lmm_fix = {\n",
    "    'single_motor': f\"EMA_SUM_{motor_target} + EMA_SUM_nonmotor\",\n",
    "    'all_motor': (\n",
    "        \"EMA_SUM_brady + EMA_SUM_tremor + \"\n",
    "        \"EMA_SUM_gait + EMA_SUM_nonmotor\"\n",
    "    )\n",
    "}\n",
    "\n",
    "FIX_EFF = 'all_motor'\n",
    "\n",
    "# Random intercepts only\n",
    "model = smf.mixedlm(\n",
    "    f\"UPDRS_SUM_{motor_target} ~ {lmm_fix[FIX_EFF]}\",\n",
    "    lmm_df,\n",
    "    groups=lmm_df[\"subid\"],\n",
    "    # re_formula=f\"~EMA_SUM_{motor_target}\",  # for random slopes for EMA motor\n",
    ")\n",
    "result = model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "## calculate explained variances\n",
    "R2_marg, R2_cond = utilsstat.calc_expl_variances(fitted_model=result)\n",
    "\n",
    "print(f\"for {motor_target}: R2_marginal {np.round(R2_marg, 3)},\"\n",
    "      f\"R2_conditional: {np.round(R2_cond, 3)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show individual differences in EMA-point vs UPDRS-change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4),\n",
    "                         sharey=True, )\n",
    "\n",
    "for i_trg, target in enumerate(['brady', 'tremor', 'gait']):\n",
    "\n",
    "    id_coefs = []\n",
    "\n",
    "    for subid in np.unique(lmm_df['subid']):\n",
    "\n",
    "        x = lmm_df[f'EMA_SUM_{target}'][lmm_df['subid'] == subid]\n",
    "        y = lmm_df[f'UPDRS_SUM_{target}'][lmm_df['subid'] == subid]\n",
    "\n",
    "        try:\n",
    "            z = np.polyfit(x, y, 1)\n",
    "            coef = z[0]\n",
    "        except:\n",
    "            if all(x == y): coef = 0\n",
    "\n",
    "        id_coefs.append(coef)\n",
    "        # plt.scatter(x, y)\n",
    "        xplot = np.arange(5)\n",
    "        # plt.plot(xplot, xplot * coef)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    axes[i_trg].hist(id_coefs)\n",
    "    axes[i_trg].set_xlabel('delta UPDRS point / EMA point')\n",
    "    axes[i_trg].set_ylabel(f'Observations for {target} (n subjects)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFP analysis (not included)\n",
    "\n",
    "to do's:\n",
    "- double check \"rest\" task is not excluding data\n",
    "- include stim-amplitude data rows to double s0 vs s1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ids = load_data.get_ids()\n",
    "\n",
    "SKIP_LFPs = {\n",
    "    'ema03': ['m0s1'],\n",
    "    'ema07': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema09': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema10': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema12': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema14': 'all',  # no m1 done, m0s1 not found in motherfolder\n",
    "    # 'ema14': ['m1s0', 'm1s1', 'm0s1'],  # ONLY m0s0; EXCLUDE?!\n",
    "    'ema15': ['m1s0', 'm1s1'],  # no m1 done: always ['m1s0', 'm1s1']\n",
    "    'ema16': ['m1s0', 'm1s1']  # ONLY m0s0; EXCLUDE?!\n",
    "    # 'ema16': 'all'  # no m1 done: always ['m1s0', 'm1s1']\n",
    "}\n",
    "\n",
    "lfp_data = {}\n",
    "\n",
    "for ema_id, COND in product(ids.index,\n",
    "                            ['m0s0', 'm0s1', 'm1s0', 'm1s1']):\n",
    "    if ema_id in SKIP_LFPs.keys():\n",
    "        if COND in SKIP_LFPs[ema_id] or SKIP_LFPs[ema_id] == 'all':\n",
    "            print(f'\\n#### SKIP {ema_id} {COND}, not percept ready ####\\n')\n",
    "            continue\n",
    "\n",
    "    sub = ids.loc[ema_id]['prc_id']\n",
    "    ses = ids.loc[ema_id]['prc_ses']\n",
    "\n",
    "    print(f'\\nGET LFP {ema_id}, {sub}, {ses}, {COND}')\n",
    "\n",
    "    # load session that corresponds to current selection\n",
    "    ### TODO: 'REST' is hardcoded currently, check for issues with task like rest&tap\n",
    "    sub_data = main_class.PerceiveData(\n",
    "        sub = sub, \n",
    "        incl_modalities=['streaming'],\n",
    "        incl_session = [ses],\n",
    "        incl_condition =[COND,],\n",
    "        incl_task = [\"rest\"],\n",
    "        import_json=False, # for addtionally loading the corresponding JSON files as source files, set to True\n",
    "        warn_for_metaNaNs=True, # True will give you a warning with rows from the metadata table with NaNs. Make sure you have filled out all columns of the file you want to load.\n",
    "        allow_NaNs_in_metadata=True,\n",
    "    )\n",
    "\n",
    "    dat = getattr(sub_data.streaming, ses)\n",
    "    # only include first two data rows (left and right STN signal)\n",
    "    dat = getattr(dat, COND).rest.run1.data.get_data()[:2, :]\n",
    "    ### TODO: include stimulation amplitude data streams to double check whether s0 vs s1 is correct\n",
    "    lfp_data[f'{ema_id}_{COND}'] = dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG_PATH = os.path.join(os.path.dirname(os.getcwd()), 'figures', 'lfp_preprocess')\n",
    "FIG_PATH = load_utils.get_onedrive_path('emaval_fig')\n",
    "print(f'CHECK FIG_PATH: {FIG_PATH}, exists? -> {os.path.exists(FIG_PATH)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_lfp_preprocess(\n",
    "    DAT,\n",
    "    SUB = 'emaXX',\n",
    "    COND = 'm0s0',\n",
    "    N_STD_OUTLIER = 3,\n",
    "    LOWPASS = 2,\n",
    "    HIGHPASS = 45,\n",
    "    SFREQ=250,\n",
    "    SHOWPLOTS=False,\n",
    "    SAVEPLOTS=True,\n",
    "):\n",
    "    lfp_times = prep_data.get_lfp_times()\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2)\n",
    "    for i, (arr, side) in enumerate(\n",
    "        zip(DAT[f'{SUB}_{COND}'][:2], ['left', 'right'])\n",
    "    ):\n",
    "        arr = arr.copy()  # do not overwrite original dict data\n",
    "\n",
    "        if ids.loc[SUB]['prc_id'] in lfp_times.keys():\n",
    "            t_start, t_end = lfp_times[ids.loc[SUB]['prc_id']][COND]['rest']\n",
    "            i_start, i_end = (t_start * 250, t_end * 250)\n",
    "            arr = arr[i_start:i_end]\n",
    "\n",
    "        ### plot raw signal\n",
    "        axes[0, i].plot(arr, color='blue', alpha=.3, label='raw filtered',)\n",
    "\n",
    "        ### handle outliers\n",
    "        sel = np.logical_or(arr > (N_STD_OUTLIER * np.std(arr)),\n",
    "                            arr < (-N_STD_OUTLIER * np.std(arr)))\n",
    "        # arr[sel] = np.nan  # replace outliers with NaNs\n",
    "        arr = arr[~sel]  # drop outliers\n",
    "        \n",
    "        ### plot resulting arr\n",
    "        axes[0, i].plot(arr, color='blue', label='cleaned',)\n",
    "        axes[0, i].set_title(f'{SUB} {COND} {side} STN', weight='bold')\n",
    "        axes[0, i].set_ylabel(f'{side}-STN activity (yVolt)')\n",
    "        xticks = np.arange(0, len(arr), 250 * 60)\n",
    "        axes[0, i].set_xticks(xticks)\n",
    "        axes[0, i].set_xticklabels(np.arange(len(xticks)))\n",
    "        axes[0, i].set_xlabel('Time (minutes)')\n",
    "        axes[0, i].set_ylim(-50, 50)\n",
    "        # axes[0, i].legend(loc='upper right', frameon=False,)  # legend\n",
    "\n",
    "        ### plot PSD\n",
    "        arr = prep_data.lfp_filter(signal=arr, low=LOWPASS, high=HIGHPASS,)\n",
    "        f, psx = welch(arr, fs=SFREQ,)\n",
    "        axes[1, i].plot(f, psx)\n",
    "        axes[1, i].set_ylabel(f'{side}-STN Power (a.u.)')\n",
    "        axes[1, i].set_xlim(0, 45)\n",
    "        axes[1, i].set_xlabel('Freq (Hz)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVEPLOTS:\n",
    "        plt.savefig(os.path.join(FIG_PATH, 'lfp_preprocess', f'PSD_check_{SUB}_{COND}'),\n",
    "                    facecolor='w', dpi=150,)\n",
    "    if SHOWPLOTS: plt.show()\n",
    "    else: plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK missing LFP sessions\n",
    "\n",
    "check motherfolder:\n",
    "- ema16, sub105: too many runs? UPDRS tasks? 3 rest m0s0, 2 rest m0s1?\n",
    "- ema14: only m0s0, leave out only one state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_done = np.unique([k.split('_')[0] for k in lfp_data.keys()])\n",
    "\n",
    "lfp_todo = [s for s in ids.index if s not in lfp_done]\n",
    "\n",
    "print(lfp_todo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in lfp_todo:\n",
    "\n",
    "    print(f'\\n{sub}  -> sub-{ids.loc[sub][\"prc_id\"]} @ {ids.loc[sub][\"prc_ses\"]}')\n",
    "    for COND in ['m0s0', 'm0s1', 'm1s0', 'm1s1']:\n",
    "        print(f'\\t{COND}')\n",
    "        sub_data = main_class.PerceiveData(\n",
    "            sub = ids.loc[sub]['prc_id'],\n",
    "            incl_modalities=['streaming'],\n",
    "            incl_session = [ids.loc[sub]['prc_ses']],\n",
    "            incl_condition =[COND,],\n",
    "            incl_task = [\"rest\"],\n",
    "            import_json=False, # for addtionally loading the corresponding JSON files as source files, set to True\n",
    "            warn_for_metaNaNs=True, # True will give you a warning with rows from the metadata table with NaNs. Make sure you have filled out all columns of the file you want to load.\n",
    "            allow_NaNs_in_metadata=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select relevant ephys epochs based on task timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_times = prep_data.get_lfp_times()\n",
    "ids = load_data.get_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 250\n",
    "sub = 'ema01'\n",
    "con = 'm0s0'\n",
    "lfp_sub = ids.loc[sub]['prc_id']\n",
    "\n",
    "rest_times = lfp_times[lfp_sub][con]['rest']\n",
    "rest_samples = [rest_times[0] * Fs, rest_times[1] * Fs]\n",
    "\n",
    "plt.plot(lfp_data[f'{sub}_{con}'][0][rest_samples[0]:rest_samples[1]])\n",
    "\n",
    "### TODO:\n",
    "# check if all seconds for available data is working\n",
    "# correct 'rest' tasks if troublesome i.e. rest&tap\n",
    "# check s0 and s1 versus stim-ampltidude time series\n",
    "# plot individual PSDs\n",
    "# calculate beta-powers X UPDRS correlations\n",
    "# draft if and if so, how to include movement parts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and save spectral preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_subs = np.unique([k.split('_')[0] for k in lfp_data.keys()])\n",
    "\n",
    "# lfp_subs = ['ema01', 'ema08']\n",
    "\n",
    "for SUB, COND in product(lfp_subs, ['m0s0', 'm0s1', 'm1s0', 'm1s1']):\n",
    "\n",
    "    print(f'\\n### {SUB}, {COND}')\n",
    "    if f'{SUB}_{COND}' not in lfp_data.keys():\n",
    "        print(f'...skip {SUB}, {COND}')\n",
    "        continue\n",
    "\n",
    "    plot_single_lfp_preprocess(SUB=SUB, COND=COND, DAT=lfp_data,\n",
    "                               N_STD_OUTLIER=6,\n",
    "                               SHOWPLOTS=False, SAVEPLOTS=True,)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
