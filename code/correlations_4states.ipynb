{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-clinic data to validate EMA with UPDRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import packages\n",
    "\n",
    "- document versions for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import importlib\n",
    "from itertools import product, compress\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.signal import welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "# print('sci-py', scipy.__version__)\n",
    "# print('sci-kit learn', sk.__version__)\n",
    "# print('matplotlib', plt_version)\n",
    "\n",
    "\"\"\"\n",
    "Python sys 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
    "pandas 2.1.1\n",
    "numpy 1.26.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_utils, load_data, prep_data\n",
    "# from PerceiveImport.classes import main_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figpath = load_utils.get_onedrive_path('emaval_fig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Import EMA and UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SINGLE CONDITION\n",
    "# CONDITION = 'm0s0'\n",
    "\n",
    "# ema_df, updrs_df = load_data.get_EMA_UPDRS_data(condition=CONDITION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_data)\n",
    "importlib.reload(load_utils)\n",
    "\n",
    "\n",
    "# list of IDs to exclude bcs data is still missing\n",
    "excl_ids = []  # 'ema31', 'ema32', 'ema33', 'ema34'\n",
    "\n",
    "# 4 CONDITIONS\n",
    "EMA, UPDRS = {}, {}\n",
    "\n",
    "for COND in ['m0s0', 'm0s1', 'm1s0', 'm1s1']:\n",
    "    ema_temp, updrs_temp = load_data.get_EMA_UPDRS_data(\n",
    "        condition=COND, CONVERT_SCORES=True,\n",
    "    )\n",
    "    EMA[COND] = ema_temp\n",
    "    UPDRS[COND] = updrs_temp\n",
    "\n",
    "    # print(f'EMA ids: {EMA[COND][\"study_id\"]}')\n",
    "    # print(f'UPDRS ids: {UPDRS[COND][\"study_id\"]}')\n",
    "\n",
    "    for ema_n_excl in excl_ids:\n",
    "        if ema_n_excl in EMA[COND]['study_id'].values:\n",
    "            drop_idx = np.where(EMA[COND]['study_id'] == ema_n_excl)[0][0]\n",
    "            EMA[COND] = EMA[COND].drop(drop_idx).reset_index(drop=True)\n",
    "            print(f'drop {ema_n_excl} in EMA, index: {drop_idx}')\n",
    "        if ema_n_excl in UPDRS[COND]['study_id'].values:\n",
    "            drop_idx = np.where(UPDRS[COND]['study_id'] == ema_n_excl)[0][0]\n",
    "            UPDRS[COND] = UPDRS[COND].drop(drop_idx).reset_index(drop=True)\n",
    "            print(f'drop {ema_n_excl} in UPDRS, index: {drop_idx}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get (mean-corrected) EMA and UPDRS values per symptom subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_data)\n",
    "\n",
    "importlib.reload(prep_data)\n",
    "\n",
    "\n",
    "sumdf = prep_data.get_sum_df(EMA_dict=EMA, UPDRS_dict=UPDRS,\n",
    "                             MEAN_CORR=True,)\n",
    "\n",
    "# sumdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split in Training and Test Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA IN TRAIN AND TEST\n",
    "\n",
    "train_subs, test_subs = prep_data.get_train_test_split(sumdf)\n",
    "\n",
    "traindf = sumdf.loc[[i for i in sumdf.index if i in train_subs]]\n",
    "\n",
    "testdf = sumdf.loc[[i for i in sumdf.index if i in test_subs]]\n",
    "\n",
    "print(traindf.shape, testdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Describe and compare Population: training vs. test cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu, ttest_rel, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train subs: {traindf.index}')\n",
    "print(f'test subs: {testdf.index}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### age, PD duration, post-op duration in two data-splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = {\n",
    "    'train': [62, 59, 42, 52, 68, 68, 56, 75, 62, 69, 55, 64, 74, 63, 48, 62, 68, 62, 71, 68, 73, 70, 67, 65],\n",
    "    'test': [56, 75, 62, 66, 56, 63, 59, 44]\n",
    "}\n",
    "\n",
    "for key, values in age.items():\n",
    "    print()\n",
    "    print(f'{key}: mean: {np.mean(values)}, std: {np.std(values)}')\n",
    "\n",
    "# comparison test vs train\n",
    "result = mannwhitneyu(age['train'], age['test'])\n",
    "print(f'Mann-Whitney U test for age: statistic={result.statistic}, p-value={result.pvalue}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_duration = {\n",
    "    'train': [7, 11, 16, 8, 8, 9, 11, 20, 11, 9, 7, 15, 16, 14, 14, 3, 21, 7, 7, 10, 5, 10, 8, 26],\n",
    "    'test': [10, 12, 16, 13, 20, 8, 11, 18]\n",
    "}\n",
    "\n",
    "for key, values in pd_duration.items():\n",
    "    print()\n",
    "    print(f'{key}: mean: {np.mean(values)}, std: {np.std(values)}')\n",
    "\n",
    "# comparison test vs train\n",
    "result = mannwhitneyu(pd_duration['train'], pd_duration['test'])\n",
    "print(f'Mann-Whitney U test for PD duration: statistic={result.statistic}, p-value={result.pvalue}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postop_months = {'train': [3, 3, 3, 3, 18, 24, 18, 12, 3, 24, 12, 3, 36, 24, 3, 3, 12, 3, 12, 3, 12, 36, 3, 3],\n",
    "                 'test': [3, 3, 18, 3, 3, 12, 38, 24]}\n",
    "\n",
    "for key, values in postop_months.items():\n",
    "    print()\n",
    "    print(f'{key}: mean: {np.mean(values)}, std: {np.std(values)}')\n",
    "\n",
    "# comparison test vs train\n",
    "result = mannwhitneyu(postop_months['train'], postop_months['test'])\n",
    "print(f'Mann-Whitney U test for post-op months: statistic={result.statistic}, p-value={result.pvalue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare therapeutic effects (UPDRS and EMA) in two data-splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean-corrected comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(traindf.keys()), \n",
    "                         sharey='row', figsize=(12, 3))\n",
    "\n",
    "yticks = [-10, -5, 0, 5, 10]\n",
    "\n",
    "for i_ft, ft in enumerate(list(testdf.keys())):\n",
    "\n",
    "    train = traindf[ft].values\n",
    "    train = train[~np.isnan(train)]\n",
    "    test = testdf[ft].values\n",
    "    test = test[~np.isnan(test)]\n",
    "\n",
    "    axes[i_ft].boxplot([train, test])\n",
    "    axes[i_ft].set_xlabel(f'#{i_ft+1}')\n",
    "\n",
    "    # do stats\n",
    "    stat, p = mannwhitneyu(train, test)\n",
    "    print(f'Variable {i_ft+1}, {ft}: stat: {stat}, p={round(p, 4)}')\n",
    "    print(f'\\tsamples sizes: # {i_ft+1}: train={len(train)}, test={len(test)}')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines[['right', 'top', 'left', 'bottom']].set_visible(False)\n",
    "    for y in yticks: ax.axhline(y, alpha=.3, color='gray',)\n",
    "\n",
    "axes[0].set_yticks(yticks)\n",
    "axes[0].set_yticklabels(yticks)\n",
    "axes[0].set_ylabel('variable change (points)')\n",
    "\n",
    "plt.suptitle('Intra-individual changes in EMA / UPDRS per therapy condition: training vs test cohort')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# plt.savefig(os.path.join(figpath, 'train_data', 'training_vs_test_vars'), dpi=450,\n",
    "#             facecolor='w',)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) EMA x UPDRS correlations\n",
    "\n",
    "\n",
    "- EMA vs UPDRS correlations\n",
    "- variance explained by non-motor domains (LMM)\n",
    "- proportionality analysis, UPDRS-III delta per point of EMA change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_COLORS = {'brady': 'orange', 'tremor': 'purple', 'gait': 'darkgreen'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_EMA_UPDRS(\n",
    "    ax, dat_df,\n",
    "    EMA_subscore = 'brady',\n",
    "    UPDRS_subscore = 'brady',\n",
    "    show_updrs_improve=True,\n",
    "    CAT_COLORS = {'brady': 'orange', 'tremor': 'purple', 'gait': 'darkgreen'},\n",
    "    FONTSIZE=14,\n",
    "):\n",
    "\n",
    "    ema_values, updrs_values = [], []\n",
    "\n",
    "    for COND in ['m0s0', 'm0s1', 'm1s0', 'm1s1']:\n",
    "\n",
    "        ema_v = dat_df[f'EMA_SUM_{EMA_subscore}_{COND}']\n",
    "        updrs_v = dat_df[f'UPDRS_SUM_{UPDRS_subscore}_{COND}']\n",
    "\n",
    "        nan_sel = np.logical_or(pd.isna(ema_v), pd.isna(updrs_v))\n",
    "        ema_v = ema_v[~nan_sel]\n",
    "        updrs_v = updrs_v[~nan_sel]\n",
    "\n",
    "        ema_values.extend(ema_v)\n",
    "        updrs_values.extend(updrs_v)\n",
    "\n",
    "    # plot UPDRS clinical IMPROVEMENT\n",
    "    if show_updrs_improve:\n",
    "        updrs_values = np.array(updrs_values) * -1\n",
    "        ax.set_xlabel(f'UPDRS-improvement\\n(points, high: less symptoms)', size=FONTSIZE, )\n",
    "    \n",
    "    else:\n",
    "        ax.set_xlabel(f'UPDRS {UPDRS_subscore}\\n(low: less symptoms)', size=FONTSIZE)\n",
    "\n",
    "\n",
    "    ax.scatter(updrs_values, ema_values, color=CAT_COLORS[EMA_subscore], alpha=0.5, s=75,)\n",
    "    ax.axhline(y=0, c='gray', alpha=0.3)\n",
    "    ax.axvline(x=0, c='gray', alpha=0.3)\n",
    "\n",
    "    R, pval = pearsonr(\n",
    "        [x for x in updrs_values if not np.isnan(x)],\n",
    "        [y for y in ema_values if not np.isnan(y)]\n",
    "    )\n",
    "\n",
    "    # ax.set_title(f'{EMA_subscore}  R: {R.round(2)}, p={pval.round(5)}')\n",
    "    ax.set_title(\n",
    "        f'{EMA_subscore}', size=FONTSIZE+4,\n",
    "        pad=10,\n",
    "        fontdict={'weight': 'bold',\n",
    "                  'color': CAT_COLORS[EMA_subscore],},\n",
    "        # bbox=dict(facecolor=\"white\", edgecolor=\"k\", boxstyle=\"round,pad=0.3\")\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(f'EMA score\\n(points, high: less symptoms)', size=FONTSIZE,)\n",
    "    ax.tick_params(axis='both', which='both', size=FONTSIZE, labelsize=FONTSIZE)\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "\n",
    "    print(f'{EMA_subscore}  R: {R.round(2)}, p={pval.round(6)}')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figname = 'Mar26_motor_corr_meanCorrvalues'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "for ax, subscore in zip(axes, ['brady', 'tremor', 'gait']):\n",
    "\n",
    "    ax = scatter_EMA_UPDRS(\n",
    "        ax=ax, dat_df=traindf,\n",
    "        EMA_subscore=subscore,\n",
    "        UPDRS_subscore=subscore,\n",
    "        show_updrs_improve=True,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(os.path.join(figpath, 'train_data', 'ema_updrs_corr', figname), dpi=300,\n",
    "#             facecolor='w',)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LMMs, including non-motor items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.stats as utilsstat\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traindf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(prep_data)\n",
    "\n",
    "\n",
    "lmm_df = prep_data.get_lmm_df(traindf)\n",
    "\n",
    "print(lmm_df.values.shape)\n",
    "\n",
    "print(lmm_df.columns)\n",
    "\n",
    "print(lmm_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utilsstat)\n",
    "\n",
    "# set target motor symptom\n",
    "motor_target = 'brady'  # 'brady', 'tremor', 'gait'\n",
    "\n",
    "lmm_fix = {\n",
    "    'single_motor': f\"EMA_SUM_{motor_target} + EMA_SUM_nonmotor\",\n",
    "    'all_motor': (\n",
    "        \"EMA_SUM_brady + EMA_SUM_tremor + \"\n",
    "        \"EMA_SUM_gait + EMA_SUM_nonmotor\"\n",
    "    )\n",
    "}\n",
    "\n",
    "FIX_EFF = 'single_motor'\n",
    "\n",
    "# Random intercepts only\n",
    "model = smf.mixedlm(\n",
    "    f\"UPDRS_SUM_{motor_target} ~ {lmm_fix[FIX_EFF]}\",\n",
    "    lmm_df,\n",
    "    groups=lmm_df[\"cond\"],\n",
    "    # re_formula=f\"~EMA_SUM_{motor_target}\",  # for random slopes for EMA motor\n",
    ")\n",
    "result = model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "## calculate explained variances\n",
    "R2_marg, R2_cond = utilsstat.calc_expl_variances(fitted_model=result)\n",
    "\n",
    "print(f\"for {motor_target}: R2_marginal {np.round(R2_marg, 3)},\"\n",
    "      f\"R2_conditional: {np.round(R2_cond, 3)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show individual differences in EMA-point vs UPDRS-change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4),\n",
    "                         sharey=True, )\n",
    "\n",
    "FONTSIZE=14\n",
    "\n",
    "for i_trg, target in enumerate(['brady', 'tremor', 'gait']):\n",
    "\n",
    "    id_coefs = []\n",
    "\n",
    "    for subid in np.unique(lmm_df['subid']):\n",
    "\n",
    "        x = lmm_df[f'EMA_SUM_{target}'][lmm_df['subid'] == subid]\n",
    "        y = lmm_df[f'UPDRS_SUM_{target}'][lmm_df['subid'] == subid]\n",
    "\n",
    "        try:\n",
    "            z = np.polyfit(x, y, 1)\n",
    "            coef = z[0]\n",
    "        except:\n",
    "            if all(x == y): coef = 0\n",
    "\n",
    "        id_coefs.append(coef)\n",
    "        xplot = np.arange(5)\n",
    "\n",
    "    print(f'{target} mean-coefs: {np.mean(id_coefs).round(2)}, std: {np.std(id_coefs).round(2)}')\n",
    "\n",
    "    axes[i_trg].hist(id_coefs, color=CAT_COLORS[target], alpha=0.5,)\n",
    "    axes[i_trg].set_xlabel('$\\\\Delta$ UPDRS-III per EMA-change\\n(points per point)', size=FONTSIZE,)\n",
    "    if i_trg == 0: axes[i_trg].set_ylabel(f'Observations (subjects)', size=FONTSIZE,)\n",
    "\n",
    "    axes[i_trg].set_title(\n",
    "    f'{target}', size=FONTSIZE+4,\n",
    "    pad=10,\n",
    "    fontdict={'weight': 'bold',\n",
    "                'color': CAT_COLORS[target],},\n",
    "    )\n",
    "    axes[i_trg].tick_params(axis='both', which='both', size=FONTSIZE, labelsize=FONTSIZE)\n",
    "    axes[i_trg].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(os.path.join(figpath, 'train_data', 'ema_updrs_corr', 'Mar2026_delta_UPDRS_EMA'), dpi=300,\n",
    "#             facecolor='w',)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Hold-out Validation: UPDRS prediction based on EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "# from sklearn.metrics import r2_score, confusion_matrix\n",
    "# from scipy.stats import f\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_true_scatter(\n",
    "    ax, y_test, y_pred, TARGET_FT, CAT_COLORS,\n",
    "    FONTSIZE=14, ax_title=None,\n",
    "):\n",
    "\n",
    "    ax.scatter(y_test, y_pred, color=CAT_COLORS[TARGET_FT], alpha=0.5, s=75,)\n",
    "\n",
    "    ax.axhline(y=0, c='gray', alpha=0.3)\n",
    "    ax.axvline(x=0, c='gray', alpha=0.3)\n",
    "\n",
    "    if not ax_title: ax_title = TARGET_FT\n",
    "    ax.set_title(\n",
    "        f'{ax_title}', size=FONTSIZE+4,\n",
    "        pad=10,\n",
    "        fontdict={\n",
    "            'weight': 'bold',\n",
    "            'color': CAT_COLORS[TARGET_FT],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(f'Observed UPDRS-III\\n(mean-corr. points)', size=FONTSIZE,)\n",
    "    ax.set_ylabel(f'Predicted UPDRS-III\\n(mean-corr. points)', size=FONTSIZE,)\n",
    "    ax.tick_params(axis='both', which='both', size=FONTSIZE, labelsize=FONTSIZE)\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ax_residuals_plot(\n",
    "    ax, y_true, y_pred,\n",
    "    FONTSIZE=14, \n",
    "):\n",
    "    residuals = y_true - y_pred\n",
    "\n",
    "    ax.scatter(y_pred, residuals, alpha=0.5, color='gray', s=75,)\n",
    "    ax.axhline(0, linestyle=\"--\")\n",
    "\n",
    "    ax.set_xlabel(\"Predicted UPDRS-III\\n(mean-corr. points)\", size=FONTSIZE,)\n",
    "    ax.set_ylabel(\"Residuals (Observed - Predicted)\", size=FONTSIZE,)\n",
    "    ax.set_title(\"Cross-validation (training data) residuals\", size=FONTSIZE,)\n",
    "    ax.tick_params(axis='both', which='both', size=FONTSIZE, labelsize=FONTSIZE)\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_cv_results(\n",
    "    fitted_models, cv_df, model_name='xgb',\n",
    "    SAVE_FIG=False, SHOW_FIG=True, figname=None,\n",
    "    CAT_COLORS = {'brady': 'orange', 'tremor': 'purple', 'gait': 'darkgreen'},\n",
    "):\n",
    "    # plot cross-validation results\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "\n",
    "    for i_ft, TARGET_FT in enumerate(['brady', 'tremor', 'gait']):\n",
    "\n",
    "        cv_df = prep_data.get_lmm_df(traindf)\n",
    "        X_train = cv_df[f'EMA_SUM_{TARGET_FT}'].values.reshape(-1, 1)\n",
    "        y_train = cv_df[f'UPDRS_SUM_{TARGET_FT}'].values\n",
    "\n",
    "        y_train_pred = fitted_models[TARGET_FT].predict(X_train)\n",
    "\n",
    "        r2 = r2_score(y_train, y_train_pred)\n",
    "        rmse = root_mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "        # print(f\"R2 for {TARGET_FT}: {r2}, RMSE: {rmse}\")\n",
    "\n",
    "    # fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        axes[i_ft, 0] = plot_pred_true_scatter(\n",
    "            ax=axes[i_ft, 0], y_test=y_train, y_pred=y_train_pred,\n",
    "            TARGET_FT=TARGET_FT, CAT_COLORS=CAT_COLORS,\n",
    "            ax_title=f'{TARGET_FT} ({model_name}): R2: {round(r2, 2)}, RMSE: {round(rmse, 2)}'\n",
    "        )\n",
    "        axes[i_ft, 1] = ax_residuals_plot(ax=axes[i_ft, 1], y_true=y_train, y_pred=y_train_pred)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVE_FIG:\n",
    "        plt.savefig(\n",
    "            os.path.join(figpath, 'train_data', 'ema_updrs_corr', figname),\n",
    "            dpi=450, facecolor='w',\n",
    "        )\n",
    "\n",
    "    if SHOW_FIG: plt.show()\n",
    "    else: plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) xgboost: non linear model\n",
    "\n",
    "- \"Gradient boosting constructs an ensemble of decision trees in a stage-wise manner, allowing modeling of nonlinear relationships and interactions between EMA items.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross-validation (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### crossvalidation single features\n",
    "# TARGET_FT = 'brady'  # 'brady', 'tremor', 'gait', 'updrs_sum'\n",
    "\n",
    "# cv_df = prep_data.get_lmm_df(traindf)\n",
    "\n",
    "# X_train = cv_df[f'EMA_SUM_{TARGET_FT}'].values.reshape(-1, 1)\n",
    "\n",
    "# if TARGET_FT == 'updrs_sum':\n",
    "#     # predict motor UPDRS change\n",
    "#     y_train = np.sum(cv_df[['UPDRS_SUM_brady', 'UPDRS_SUM_tremor',\n",
    "#                               'UPDRS_SUM_gait']], axis=1).values\n",
    "# else:\n",
    "#     y_train = cv_df[f'UPDRS_SUM_{TARGET_FT}'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cv_xgb(X_train, y_train):\n",
    "    \n",
    "\n",
    "    xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [2, 3, 4],\n",
    "        \"learning_rate\": [0.05, 0.1],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.8, 1.0],\n",
    "\n",
    "    }\n",
    "\n",
    "    grid_gb = GridSearchCV(\n",
    "        xgb,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"r2\"\n",
    "    )\n",
    "\n",
    "    grid_gb.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_gb.best_estimator_\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidation result dicts\n",
    "xgb_models, xgb_hparams = {}, {}\n",
    "\n",
    "# TARGET_FT = 'brady'  # 'brady', 'tremor', 'gait', 'updrs_sum'\n",
    "\n",
    "for TARGET_FT in ['brady', 'tremor', 'gait']:\n",
    "    cv_df = prep_data.get_lmm_df(traindf)\n",
    "    X_train = cv_df[f'EMA_SUM_{TARGET_FT}'].values.reshape(-1, 1)\n",
    "    y_train = cv_df[f'UPDRS_SUM_{TARGET_FT}'].values\n",
    "\n",
    "    # fit xgb model in crossvalidation grid search\n",
    "    xgb_models[TARGET_FT] = fit_cv_xgb(X_train, y_train)\n",
    "    # extract hyperparameters\n",
    "    xgb_hparams[TARGET_FT] = xgb_models[TARGET_FT].get_params()\n",
    "\n",
    "    # print(f\"Optimal hyperparameters for {TARGET_FT}:\")\n",
    "    # for k, v in xgb_hparams[TARGET_FT].items():\n",
    "    #     print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cv_results(\n",
    "    fitted_models=xgb_models, cv_df=cv_df, model_name='xgb',\n",
    "    SHOW_FIG=False, SAVE_FIG=True, figname='Mar2026_crossval_xgb',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) Linear regression cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cv_regr(X_train, y_train):\n",
    "    \n",
    "    # Pipeline: scaling + ElasticNet\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", ElasticNet(max_iter=10000, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Hyperparameter grid\n",
    "    param_grid = {\n",
    "        \"model__alpha\": [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        \"model__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    }\n",
    "\n",
    "    grid_rg = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"r2\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_rg.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_rg.best_estimator_\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidation result dicts\n",
    "regr_models, regr_hparams = {}, {}\n",
    "\n",
    "\n",
    "for TARGET_FT in ['brady', 'tremor', 'gait']:\n",
    "    cv_df = prep_data.get_lmm_df(traindf)\n",
    "    X_train = cv_df[f'EMA_SUM_{TARGET_FT}'].values.reshape(-1, 1)\n",
    "    y_train = cv_df[f'UPDRS_SUM_{TARGET_FT}'].values\n",
    "\n",
    "    # fit regression model in crossvalidation grid search\n",
    "    regr_models[TARGET_FT] = fit_cv_regr(X_train, y_train)\n",
    "    # extract hyperparameters\n",
    "    regr_hparams[TARGET_FT] = regr_models[TARGET_FT].get_params()\n",
    "\n",
    "# # extract optimal hyperparameters\n",
    "# best_params = grid.best_params_\n",
    "# best_alpha = best_params[\"model__alpha\"]\n",
    "# best_l1_ratio = best_params[\"model__l1_ratio\"]\n",
    "\n",
    "# print(\"Optimal alpha:\", best_alpha)\n",
    "# print(\"Optimal l1_ratio:\", best_l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cv_results(\n",
    "    fitted_models=regr_models, cv_df=cv_df, model_name='regr',\n",
    "    SHOW_FIG=False, SAVE_FIG=True, figname='Mar2026_crossval_regr',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c) Holdout validation with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_holdout_results = {\n",
    "    'r2': {},\n",
    "    'rmse': {},\n",
    "    'y_test_true': {},\n",
    "    'y_test_pred': {},\n",
    "}\n",
    "\n",
    "for TARGET_FT in ['brady', 'tremor', 'gait']:\n",
    "    # training cohort for fitting final models\n",
    "    cv_df = prep_data.get_lmm_df(traindf)\n",
    "    X_train = cv_df[f'EMA_SUM_{TARGET_FT}'].values.reshape(-1, 1)\n",
    "    y_train = cv_df[f'UPDRS_SUM_{TARGET_FT}'].values\n",
    "    # get optimal model\n",
    "    opt_model0 = xgb_models[TARGET_FT]  # direct from saved model\n",
    "    opt_hyperparams = xgb_hparams[TARGET_FT]  # from hyperparameter dict, for later permutation\n",
    "    opt_model = XGBRegressor(\n",
    "        **opt_hyperparams\n",
    "    )\n",
    "    opt_model.fit(X_train, y_train)\n",
    "\n",
    "    # testing cohort for evaluating final models\n",
    "    ho_df = prep_data.get_lmm_df(testdf)\n",
    "    X_test = ho_df[f'EMA_SUM_{TARGET_FT}'].values.reshape(-1, 1)\n",
    "\n",
    "    # observed test values\n",
    "    y_test_true = ho_df[f'UPDRS_SUM_{TARGET_FT}'].values\n",
    "\n",
    "    y_test_pred = opt_model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test_true, y_test_pred)\n",
    "    rmse = root_mean_squared_error(y_test_true, y_test_pred)\n",
    "    true_holdout_results['r2'][TARGET_FT] = r2\n",
    "    true_holdout_results['rmse'][TARGET_FT] = rmse\n",
    "    true_holdout_results['y_test_true'][TARGET_FT] = y_test_true\n",
    "    true_holdout_results['y_test_pred'][TARGET_FT] = y_test_pred\n",
    "\n",
    "    print(f\"Test set performance for {TARGET_FT}: R2: {r2}, RMSE: {rmse}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PERM = 500\n",
    "\n",
    "perm_results_r2 = {ft: [] for ft in ['brady', 'tremor', 'gait']}\n",
    "\n",
    "for TARGET_FT in ['brady', 'tremor', 'gait']:\n",
    "    \n",
    "    for i_perm in range(N_PERM):\n",
    "        \n",
    "        np.random.seed(i_perm)\n",
    "        # training cohort for fitting final models\n",
    "        cv_df = prep_data.get_lmm_df(traindf)\n",
    "        X_train = cv_df[f'EMA_SUM_{TARGET_FT}'].values.reshape(-1, 1)\n",
    "        np.random.shuffle(X_train)  # shuffle EMA values to break true association with UPDRS\n",
    "        y_train = cv_df[f'UPDRS_SUM_{TARGET_FT}'].values\n",
    "        \n",
    "        # get optimal model\n",
    "        opt_hyperparams = xgb_hparams[TARGET_FT]  # from hyperparameter dict, for later permutation\n",
    "        opt_model = XGBRegressor(\n",
    "            **opt_hyperparams\n",
    "        )\n",
    "        opt_model.fit(X_train, y_train)  # with shuffled randomized training X\n",
    "\n",
    "        # testing cohort for evaluating final models\n",
    "        ho_df = prep_data.get_lmm_df(testdf)\n",
    "        X_test = ho_df[f'EMA_SUM_{TARGET_FT}'].values.reshape(-1, 1)\n",
    "\n",
    "        # observed test values\n",
    "        y_test_true = ho_df[f'UPDRS_SUM_{TARGET_FT}'].values\n",
    "\n",
    "        y_test_pred = opt_model.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test_true, y_test_pred)\n",
    "        perm_results_r2[TARGET_FT].append(r2)\n",
    "\n",
    "        # rmse = root_mean_squared_error(y_test_true, y_test_pred)\n",
    "        print(f\"Permutation {i_perm+1}/{N_PERM} for {TARGET_FT}: R2: {r2},\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot holdout results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ft in ['brady', 'tremor', 'gait']:\n",
    "\n",
    "    print(f\"{ft} permutation R2: mean: {np.mean(perm_results_r2[ft]).round(3)}, std: {np.std(perm_results_r2[ft]).round(3)}\")\n",
    "    p_value = np.mean(np.array(perm_results_r2[ft]) >= true_holdout_results[ft]['r2'])\n",
    "\n",
    "    print(f\"Permutation p-value for {ft}: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_holdout_results(\n",
    "    true_holdout_results, perm_results_r2=None,\n",
    "    CAT_COLORS = {'brady': 'orange', 'tremor': 'purple', 'gait': 'darkgreen'},\n",
    "    SAVE_FIG=False, SHOW_FIG=True, figname=None,\n",
    "    # FONTSIZE=14,\n",
    "):\n",
    "    \n",
    "    domains = list(CAT_COLORS.keys())\n",
    "    titles = {'brady': \"Bradykinesia\", 'tremor': \"Tremor\", 'gait': \"Gait\"}\n",
    "\n",
    "    y_true_list = [true_holdout_results['y_test_true'][d] for d in domains]\n",
    "    y_pred_list = [true_holdout_results['y_test_pred'][d] for d in domains]\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        \"font.size\": 10,\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"xtick.labelsize\": 9,\n",
    "        \"ytick.labelsize\": 9,\n",
    "        \"figure.dpi\": 300\n",
    "    })\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 3, figsize=(12, 4),\n",
    "        # sharex=True, sharey=True,\n",
    "    )\n",
    "\n",
    "    for ax, y_true, y_pred, sympt in zip(axes, y_true_list, y_pred_list, domains):\n",
    "\n",
    "        # Scatter\n",
    "        ax.scatter(y_true, y_pred, alpha=0.7, s=75, zorder=1,\n",
    "                   color=CAT_COLORS[sympt], )\n",
    "\n",
    "        # Axis limits\n",
    "        min_val = min(y_true.min(), y_pred.min())\n",
    "        max_val = max(y_true.max(), y_pred.max())\n",
    "        buffer = 0.05 * (max_val - min_val)\n",
    "        lims = [min_val - buffer, max_val + buffer]\n",
    "\n",
    "        # Identity line\n",
    "        ax.plot(lims, lims, linestyle=\"--\", linewidth=2, color='gray', zorder=0, alpha=.7,)\n",
    "        ax.set_xlim(lims)\n",
    "        ax.set_ylim(lims)\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "        # Metrics\n",
    "        r2 = true_holdout_results['r2'][sympt]\n",
    "        rmse = true_holdout_results['rmse'][sympt]\n",
    "\n",
    "        if perm_results_r2 is None:\n",
    "            boxtext = f\"$R^2$ = {r2:.2f}\\nRMSE = {rmse:.2f}\"\n",
    "        else:\n",
    "            p_value = np.mean(np.array(perm_results_r2[sympt]) >= r2)\n",
    "            boxtext = f\"$R^2$ = {r2:.2f}\\nRMSE = {rmse:.2f}\\np={p_value:.3f}\"\n",
    "        ax.text(0.05, 0.95,\n",
    "                boxtext,\n",
    "                transform=ax.transAxes,\n",
    "                verticalalignment=\"top\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "        ax.set_title(titles[sympt], fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Observed UPDRS fluctuation (points)\")\n",
    "        ax.grid(False)\n",
    "\n",
    "    axes[0].set_ylabel(\"Predicted UPDRS fluctuation (points)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save as vector graphics for journal submission\n",
    "    if SAVE_FIG and figname is not None:\n",
    "        fig_path = os.path.join(figpath, 'ema_updrs_holdout', figname)\n",
    "        for ext in ['', '.pdf', '.svg']:\n",
    "            plt.savefig(fig_path + ext, bbox_inches=\"tight\")\n",
    "\n",
    "    if SHOW_FIG: plt.show()\n",
    "    else: plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_holdout_results(\n",
    "    true_holdout_results=true_holdout_results,\n",
    "    perm_results_r2=perm_results_r2,\n",
    "    SAVE_FIG=True, SHOW_FIG=False, figname='Mar2026_holdout_scatters',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### plot significancies from permutations\n",
    "\n",
    "# def plot_holdout_signs():\n",
    "#     fig, axes = plt.subplots(1, len(perm_stats.keys()), figsize=(12, 4))\n",
    "\n",
    "#     for i_ax, metr in enumerate(list(perm_stats.keys())):\n",
    "\n",
    "#         axes[i_ax].hist(perm_stats[metr], color='gray', alpha=.5,)\n",
    "#         axes[i_ax].axvline(np.percentile(perm_stats[metr], 95),\n",
    "#                         color='orange', alpha=.8, lw=3,\n",
    "#                         label='permuted\\nalpha 0.05',)\n",
    "        \n",
    "#         axes[i_ax].axvline(true_stats[metr],\n",
    "#                         color='purple', alpha=.5, lw=1,\n",
    "#                         label='prediction',)\n",
    "        \n",
    "#         p_calc = sum(np.array(perm_stats[metr]) > true_stats[metr]) / len(perm_stats[metr])\n",
    "#         print(f'metric {metr}: p = {np.round(p_calc, 3)}')\n",
    "\n",
    "#         axes[i_ax].set_xlabel(f'{metr} score', size=14,)\n",
    "\n",
    "#         axes[i_ax].set_ylabel('count (n)', size=14)\n",
    "\n",
    "#         axes[i_ax].tick_params(axis='both', size=14, labelsize=14,)\n",
    "#         axes[i_ax].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#     axes[1].legend(frameon=False, fontsize=14,\n",
    "#                 bbox_to_anchor=(.95, .5), loc='center left')\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # plt.savefig(os.path.join(load_utils.get_onedrive_path('figures'),\n",
    "# #              'ema_updrs_corr', f'holdOut_updrsSum_{N_PERM}permStats'),\n",
    "# #              dpi=300, facecolor='w',)\n",
    "\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
